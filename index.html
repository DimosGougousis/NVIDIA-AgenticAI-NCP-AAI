<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="preconnect" href="https://images.nvidia.com" crossorigin/>
  <link rel="preload" href="https://images.nvidia.com/etc/designs/nvidiaGDC/clientlibs_base/fonts/nvidia-sans/NALA/var/NVIDIASansVF_NALA_W_Wght.woff2" as="font" type="font/woff2" crossorigin/>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NVIDIA NCP-AAI: Agentic AI Professional ‚Äî Complete Study Guide</title>
  <meta name="description" content="Comprehensive study guide for the NVIDIA-Certified Professional: Agentic AI (NCP-AAI) exam. Covers all 10 domains with key concepts, frameworks, code examples, and 100+ practice questions." />
  <style>
    /* ‚îÄ‚îÄ NVIDIA Sans Font ‚îÄ‚îÄ */
    @font-face {
      font-family: 'NVIDIA Sans';
      src: url('https://images.nvidia.com/etc/designs/nvidiaGDC/clientlibs_base/fonts/nvidia-sans/NALA/var/NVIDIASansVF_NALA_W_Wght.woff2') format('woff2');
      font-weight: 100 900;
      font-style: normal;
      font-display: swap;
    }

    /* ‚îÄ‚îÄ NVIDIA Design Tokens ‚îÄ‚îÄ */
    :root {
      --nv-green:   #76b900;
      --nv-green-d: #5a8f00;
      --nv-green-l: #96db00;
      --nv-black:   #000000;
      --nv-dark:    #111111;
      --nv-darker:  #0a0a0a;
      --nv-gray:    #1a1a1a;
      --nv-light:   #f5f5f5;
      --nv-white:   #ffffff;
      --nv-text:    #cccccc;
      --nv-muted:   #777777;
      --nv-border:  #1e1e1e;
      --nv-card:    #111111;
      --nv-accent:  #00b4d8;
      --nv-warn:    #ff9800;
      --nv-correct: #4caf50;
      --nv-wrong:   #f44336;
      --sidebar-w:  280px;
      --topbar-h:   60px;
      --radius:     4px;
      --transition: 0.2s ease;
    }
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
    html { scroll-behavior: smooth; }
    body { font-family: 'NVIDIA Sans', 'Helvetica Neue', Arial, system-ui, sans-serif; background: var(--nv-black); color: var(--nv-text); line-height: 1.6; overflow-x: hidden; }
    a { color: var(--nv-green); text-decoration: none; }
    a:hover { color: var(--nv-green-l); text-decoration: none; }

    /* ‚îÄ‚îÄ Top Bar ‚îÄ‚îÄ */
    #topbar { position: fixed; top: 0; left: 0; right: 0; height: var(--topbar-h); background: #000; border-bottom: 1px solid var(--nv-border); display: flex; align-items: center; justify-content: space-between; padding: 0 28px; z-index: 1000; }
    .brand { display: flex; align-items: center; gap: 16px; }
    .brand svg { width: 48px; height: 32px; flex-shrink: 0; }
    .brand-text { display: flex; flex-direction: column; }
    .cert-label { font-size: 9px; font-weight: 700; letter-spacing: 2.5px; color: var(--nv-muted); text-transform: uppercase; }
    .cert-title { font-size: 14px; font-weight: 600; color: var(--nv-white); line-height: 1.2; }
    .topbar-actions { display: flex; align-items: center; gap: 10px; }
    .btn { display: inline-flex; align-items: center; gap: 6px; padding: 9px 22px; border-radius: 24px; font-size: 13px; font-weight: 600; cursor: pointer; border: none; transition: all var(--transition); text-decoration: none; font-family: inherit; letter-spacing: 0.2px; }
    .btn-primary { background: var(--nv-green); color: #000; }
    .btn-primary:hover { background: var(--nv-green-l); text-decoration: none; color: #000; transform: none; }
    .btn-outline { background: transparent; color: var(--nv-white); border: 1px solid rgba(255,255,255,0.25); }
    .btn-outline:hover { background: rgba(255,255,255,0.06); border-color: rgba(255,255,255,0.4); text-decoration: none; color: var(--nv-white); }
    .btn-sm { padding: 7px 18px; font-size: 12px; }
    #menu-toggle { display: none; background: transparent; border: none; color: var(--nv-white); cursor: pointer; padding: 8px; align-items: center; justify-content: center; }
    #progress-bar { position: fixed; top: var(--topbar-h); left: 0; height: 2px; background: var(--nv-green); width: 0%; z-index: 999; transition: width 0.3s ease; }

    /* ‚îÄ‚îÄ Sidebar ‚îÄ‚îÄ */
    #sidebar { position: fixed; top: var(--topbar-h); left: 0; bottom: 0; width: var(--sidebar-w); background: #000; border-right: 1px solid var(--nv-border); overflow-y: auto; z-index: 900; transition: transform var(--transition); }
    #sidebar::-webkit-scrollbar { width: 3px; }
    #sidebar::-webkit-scrollbar-track { background: transparent; }
    #sidebar::-webkit-scrollbar-thumb { background: #2a2a2a; border-radius: 2px; }
    .sidebar-header { padding: 20px 16px 12px; border-bottom: 1px solid var(--nv-border); }
    .sidebar-header h3 { font-size: 9px; font-weight: 700; letter-spacing: 2.5px; text-transform: uppercase; color: var(--nv-muted); }
    .sidebar-search { padding: 12px 16px; border-bottom: 1px solid var(--nv-border); }
    .sidebar-search input { width: 100%; padding: 7px 14px; background: rgba(255,255,255,0.04); border: 1px solid var(--nv-border); border-radius: 20px; color: var(--nv-text); font-size: 12px; outline: none; font-family: inherit; }
    .sidebar-search input:focus { border-color: rgba(118,185,0,0.5); }
    .sidebar-search input::placeholder { color: var(--nv-muted); }
    .sidebar-nav { padding: 6px 0; }
    .nav-section { margin-bottom: 1px; }
    .nav-chapter-btn { width: 100%; display: flex; align-items: center; gap: 10px; padding: 9px 16px; background: transparent; border: none; color: var(--nv-muted); cursor: pointer; text-align: left; font-size: 12px; font-weight: 500; transition: all var(--transition); border-left: 2px solid transparent; font-family: inherit; }
    .nav-chapter-btn:hover { background: rgba(255,255,255,0.03); color: var(--nv-white); border-left-color: transparent; }
    .nav-chapter-btn.active { background: rgba(118,185,0,0.07); border-left-color: var(--nv-green); color: var(--nv-white); }
    .nav-chapter-btn .ch-num { display: inline-flex; align-items: center; justify-content: center; width: 20px; height: 20px; border-radius: 3px; background: rgba(255,255,255,0.07); font-size: 10px; font-weight: 700; flex-shrink: 0; color: var(--nv-muted); }
    .nav-chapter-btn.active .ch-num { background: var(--nv-green); color: #000; }
    .nav-chapter-btn:hover .ch-num { color: var(--nv-white); }
    .nav-chapter-btn .ch-weight { margin-left: auto; font-size: 10px; color: var(--nv-muted); font-weight: 400; flex-shrink: 0; }
    .nav-sub { display: none; padding-left: 46px; padding-bottom: 4px; }
    .nav-sub.open { display: block; }
    .nav-sub a { display: block; padding: 4px 8px; font-size: 11px; color: var(--nv-muted); border-radius: 3px; transition: color var(--transition); }
    .nav-sub a:hover { color: var(--nv-green); text-decoration: none; }
    .nav-divider { height: 1px; background: var(--nv-border); margin: 6px 0; }
    .nav-special-btn { width: 100%; display: flex; align-items: center; gap: 10px; padding: 9px 16px; background: transparent; border: none; color: var(--nv-green); cursor: pointer; text-align: left; font-size: 12px; font-weight: 600; transition: all var(--transition); border-left: 2px solid transparent; font-family: inherit; }
    .nav-special-btn:hover { background: rgba(118,185,0,0.05); }
    .nav-special-btn.active { background: rgba(118,185,0,0.08); border-left-color: var(--nv-green); }

    /* ‚îÄ‚îÄ Main ‚îÄ‚îÄ */
    #main { margin-left: var(--sidebar-w); margin-top: var(--topbar-h); min-height: calc(100vh - var(--topbar-h)); }
    .page { display: none; }
    .page.active { display: block; animation: fadeIn 0.2s ease; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(8px); } to { opacity: 1; transform: translateY(0); } }

    /* ‚îÄ‚îÄ Hero ‚îÄ‚îÄ */
    #hero { background: #000; padding: 88px 56px 72px; border-bottom: 1px solid var(--nv-border); position: relative; overflow: hidden; }
    #hero::before { content: ''; position: absolute; top: -150px; right: -80px; width: 800px; height: 800px; background: radial-gradient(circle, rgba(118,185,0,0.05) 0%, transparent 65%); pointer-events: none; }
    #hero::after { content: ''; position: absolute; bottom: -200px; left: -100px; width: 600px; height: 600px; background: radial-gradient(circle, rgba(0,180,216,0.03) 0%, transparent 60%); pointer-events: none; }
    .hero-badge { display: inline-flex; align-items: center; gap: 8px; padding: 5px 16px; background: rgba(118,185,0,0.1); border: 1px solid rgba(118,185,0,0.2); border-radius: 24px; font-size: 10px; font-weight: 700; color: var(--nv-green); letter-spacing: 2px; text-transform: uppercase; margin-bottom: 32px; }
    #hero h1 { font-size: clamp(34px, 4.5vw, 60px); font-weight: 900; color: var(--nv-white); line-height: 1.08; margin-bottom: 20px; letter-spacing: -1px; }
    #hero h1 span { color: var(--nv-green); }
    #hero p { font-size: 17px; color: var(--nv-muted); max-width: 620px; margin-bottom: 44px; line-height: 1.65; font-weight: 400; }
    .hero-stats { display: flex; flex-wrap: wrap; gap: 12px; margin-bottom: 44px; }
    .hero-stat { background: rgba(255,255,255,0.03); border: 1px solid var(--nv-border); border-radius: var(--radius); padding: 16px 24px; min-width: 120px; }
    .hero-stat .stat-val { font-size: 30px; font-weight: 800; color: var(--nv-green); line-height: 1; }
    .hero-stat .stat-lbl { font-size: 11px; color: var(--nv-muted); margin-top: 5px; letter-spacing: 0.3px; }
    .hero-actions { display: flex; flex-wrap: wrap; gap: 12px; }

    /* ‚îÄ‚îÄ Blueprint Grid ‚îÄ‚îÄ */
    .blueprint-section-header { padding: 36px 56px 4px; }
    .blueprint-section-header h2 { font-size: 11px; font-weight: 700; letter-spacing: 2.5px; text-transform: uppercase; color: var(--nv-muted); }
    .blueprint-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(280px, 1fr)); gap: 1px; background: var(--nv-border); border-top: 1px solid var(--nv-border); border-bottom: 1px solid var(--nv-border); }
    .blueprint-card { background: #000; padding: 28px 24px; cursor: pointer; transition: background var(--transition); position: relative; overflow: hidden; }
    .blueprint-card::after { content: ''; position: absolute; top: 0; left: 0; right: 0; height: 1px; background: var(--nv-green); transform: scaleX(0); transform-origin: left; transition: transform 0.25s ease; }
    .blueprint-card:hover { background: rgba(118,185,0,0.03); }
    .blueprint-card:hover::after { transform: scaleX(1); }
    .card-header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 14px; }
    .ch-badge { font-size: 9px; font-weight: 700; color: var(--nv-muted); text-transform: uppercase; letter-spacing: 2px; }
    .weight-badge { background: rgba(118,185,0,0.1); color: var(--nv-green); font-size: 11px; font-weight: 700; padding: 3px 10px; border-radius: 10px; }
    .blueprint-card h3 { font-size: 15px; font-weight: 700; color: var(--nv-white); margin-bottom: 10px; line-height: 1.3; }
    .blueprint-card p { font-size: 12px; color: var(--nv-muted); line-height: 1.6; }
    .card-footer { margin-top: 18px; display: flex; align-items: center; gap: 6px; font-size: 11px; color: var(--nv-green); font-weight: 600; letter-spacing: 0.3px; }

    /* ‚îÄ‚îÄ Chapter Pages ‚îÄ‚îÄ */
    .chapter-page { padding: 52px 56px; }
    .chapter-header { margin-bottom: 44px; padding-bottom: 28px; border-bottom: 1px solid var(--nv-border); }
    .ch-meta { display: flex; align-items: center; gap: 10px; margin-bottom: 18px; flex-wrap: wrap; }
    .tag { display: inline-flex; align-items: center; padding: 4px 12px; border-radius: 12px; font-size: 10px; font-weight: 700; letter-spacing: 0.5px; text-transform: uppercase; }
    .tag-green { background: rgba(118,185,0,0.1); color: var(--nv-green); }
    .tag-blue  { background: rgba(0,180,216,0.1); color: var(--nv-accent); }
    .tag-warn  { background: rgba(255,152,0,0.1); color: var(--nv-warn); }
    .chapter-header h1 { font-size: clamp(26px, 3.5vw, 44px); font-weight: 800; color: var(--nv-white); margin-bottom: 14px; line-height: 1.12; letter-spacing: -0.5px; }
    .chapter-header .ch-desc { font-size: 15px; color: var(--nv-muted); max-width: 820px; line-height: 1.7; }

    /* ‚îÄ‚îÄ Content Sections ‚îÄ‚îÄ */
    .content-section { background: var(--nv-dark); border: 1px solid var(--nv-border); border-radius: 2px; padding: 28px 32px; margin-bottom: 16px; }
    .content-section h2 { font-size: 17px; font-weight: 700; color: var(--nv-white); margin-bottom: 20px; display: flex; align-items: center; gap: 10px; }
    .section-icon { width: 30px; height: 30px; border-radius: 4px; background: rgba(118,185,0,0.1); display: flex; align-items: center; justify-content: center; font-size: 14px; flex-shrink: 0; }
    .content-section h3 { font-size: 11px; font-weight: 700; color: var(--nv-green); margin: 24px 0 10px; text-transform: uppercase; letter-spacing: 1.5px; }
    .content-section p { color: var(--nv-text); margin-bottom: 12px; line-height: 1.75; }

    /* ‚îÄ‚îÄ Concept Grid ‚îÄ‚îÄ */
    .concept-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(240px, 1fr)); gap: 1px; margin-top: 20px; background: var(--nv-border); }
    .concept-card { background: #000; padding: 18px 20px; transition: background var(--transition); }
    .concept-card:hover { background: rgba(118,185,0,0.03); }
    .concept-name { font-size: 13px; font-weight: 700; color: var(--nv-white); margin-bottom: 7px; }
    .concept-def { font-size: 12px; color: var(--nv-muted); line-height: 1.6; }

    /* ‚îÄ‚îÄ Subtopics ‚îÄ‚îÄ */
    .subtopics-list { list-style: none; }
    .subtopics-list li { padding: 14px 0; border-bottom: 1px solid var(--nv-border); display: flex; gap: 16px; }
    .subtopics-list li:last-child { border-bottom: none; }
    .subtopic-num { display: inline-flex; align-items: center; justify-content: center; width: 26px; height: 26px; border-radius: 3px; background: rgba(118,185,0,0.1); color: var(--nv-green); font-size: 11px; font-weight: 700; flex-shrink: 0; margin-top: 2px; }
    .subtopic-content .subtopic-title { font-size: 14px; font-weight: 700; color: var(--nv-white); margin-bottom: 5px; }
    .subtopic-content .subtopic-desc { font-size: 13px; color: var(--nv-muted); line-height: 1.65; }

    /* ‚îÄ‚îÄ Frameworks Table ‚îÄ‚îÄ */
    .frameworks-table { width: 100%; border-collapse: collapse; margin-top: 16px; font-size: 13px; }
    .frameworks-table th { background: rgba(118,185,0,0.07); color: var(--nv-green); font-weight: 700; padding: 11px 16px; text-align: left; border-bottom: 1px solid var(--nv-green); font-size: 10px; text-transform: uppercase; letter-spacing: 1.5px; }
    .frameworks-table td { padding: 11px 16px; border-bottom: 1px solid var(--nv-border); color: var(--nv-text); vertical-align: top; }
    .frameworks-table tr:hover td { background: rgba(255,255,255,0.02); }

    /* ‚îÄ‚îÄ Resources ‚îÄ‚îÄ */
    .resources-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(260px, 1fr)); gap: 12px; margin-top: 16px; }
    .resource-card { background: var(--nv-dark); border: 1px solid var(--nv-border); border-radius: 2px; padding: 16px; display: flex; align-items: flex-start; gap: 12px; transition: all var(--transition); }
    .resource-card:hover { border-color: rgba(118,185,0,0.3); background: rgba(118,185,0,0.02); }
    .resource-icon { width: 32px; height: 32px; border-radius: 4px; display: flex; align-items: center; justify-content: center; font-size: 15px; flex-shrink: 0; }
    .resource-icon.nvidia { background: rgba(118,185,0,0.1); }
    .resource-icon.external { background: rgba(0,180,216,0.1); }
    .resource-title { font-size: 13px; font-weight: 600; color: var(--nv-white); margin-bottom: 3px; }
    .resource-type { font-size: 11px; color: var(--nv-muted); }

    /* ‚îÄ‚îÄ Callout ‚îÄ‚îÄ */
    .callout { border-radius: 2px; padding: 16px 20px; margin: 16px 0; display: flex; gap: 14px; align-items: flex-start; }
    .callout-tip { background: rgba(118,185,0,0.05); border-left: 3px solid var(--nv-green); }
    .callout-info { background: rgba(0,180,216,0.05); border-left: 3px solid var(--nv-accent); }
    .callout-warn { background: rgba(255,152,0,0.05); border-left: 3px solid var(--nv-warn); }
    .callout-icon { font-size: 17px; flex-shrink: 0; margin-top: 2px; }
    .callout-content { font-size: 13px; color: var(--nv-text); line-height: 1.65; }
    .callout-content strong { color: var(--nv-white); }

    /* ‚îÄ‚îÄ Code Block ‚îÄ‚îÄ */
    .code-block { background: #050505; border: 1px solid var(--nv-border); border-radius: 2px; padding: 20px; margin: 16px 0; overflow-x: auto; font-family: 'Consolas', 'Monaco', 'JetBrains Mono', monospace; font-size: 13px; line-height: 1.65; }
    .code-header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 14px; padding-bottom: 10px; border-bottom: 1px solid var(--nv-border); }
    .code-lang { font-size: 9px; color: var(--nv-muted); text-transform: uppercase; letter-spacing: 2px; }
    .code-block pre { color: #d4d4d4; white-space: pre-wrap; word-break: break-word; }
    .kw { color: #ff7b72; } .str { color: #a5d6ff; } .cm { color: #555; } .fn { color: #d2a8ff; } .var { color: #ffa657; } .num { color: #79c0ff; }

    /* ‚îÄ‚îÄ Architecture Diagram ‚îÄ‚îÄ */
    .arch-diagram { background: var(--nv-dark); border: 1px solid var(--nv-border); border-radius: 2px; padding: 24px; margin: 16px 0; text-align: center; }

    /* ‚îÄ‚îÄ Practice Tests ‚îÄ‚îÄ */
    .practice-section { background: var(--nv-dark); border: 1px solid var(--nv-border); border-radius: 2px; padding: 28px 32px; margin-bottom: 16px; }
    .practice-header { display: flex; align-items: center; justify-content: space-between; margin-bottom: 24px; flex-wrap: wrap; gap: 12px; }
    .practice-header h2 { font-size: 17px; font-weight: 700; color: var(--nv-white); display: flex; align-items: center; gap: 10px; }
    .practice-stats { display: flex; gap: 16px; align-items: center; }
    .practice-stat { font-size: 13px; color: var(--nv-muted); }
    .practice-stat span { color: var(--nv-green); font-weight: 700; }
    .quiz-controls { display: flex; gap: 10px; margin-bottom: 20px; flex-wrap: wrap; }
    .question-card { background: rgba(255,255,255,0.015); border: 1px solid var(--nv-border); border-radius: 2px; padding: 22px 26px; margin-bottom: 14px; transition: border-color var(--transition); }
    .question-card.answered-correct { border-color: var(--nv-correct); }
    .question-card.answered-wrong { border-color: var(--nv-wrong); }
    .question-num { font-size: 9px; font-weight: 700; color: var(--nv-muted); text-transform: uppercase; letter-spacing: 2px; margin-bottom: 12px; }
    .question-text { font-size: 15px; font-weight: 600; color: var(--nv-white); margin-bottom: 18px; line-height: 1.5; }
    .options-list { list-style: none; }
    .option-item { display: flex; align-items: flex-start; gap: 12px; padding: 11px 16px; border-radius: 2px; margin-bottom: 8px; cursor: pointer; border: 1px solid var(--nv-border); transition: all var(--transition); background: transparent; }
    .option-item:hover { border-color: rgba(118,185,0,0.35); background: rgba(118,185,0,0.03); }
    .option-item.selected { border-color: var(--nv-accent); background: rgba(0,180,216,0.05); }
    .option-item.correct { border-color: var(--nv-correct); background: rgba(76,175,80,0.06); }
    .option-item.wrong { border-color: var(--nv-wrong); background: rgba(244,67,54,0.05); }
    .option-letter { display: inline-flex; align-items: center; justify-content: center; width: 24px; height: 24px; border-radius: 3px; background: rgba(255,255,255,0.06); font-size: 11px; font-weight: 700; color: var(--nv-muted); flex-shrink: 0; }
    .option-item.selected .option-letter { background: var(--nv-accent); color: #fff; }
    .option-item.correct .option-letter { background: var(--nv-correct); color: #fff; }
    .option-item.wrong .option-letter { background: var(--nv-wrong); color: #fff; }
    .option-text { font-size: 14px; color: var(--nv-text); line-height: 1.45; }
    .explanation-box { display: none; margin-top: 14px; padding: 14px 16px; background: rgba(118,185,0,0.04); border: 1px solid rgba(118,185,0,0.15); border-radius: 2px; font-size: 13px; color: var(--nv-text); line-height: 1.65; }
    .explanation-box.show { display: block; }
    .explanation-box strong { color: var(--nv-green); }
    .question-actions { display: flex; gap: 10px; margin-top: 14px; flex-wrap: wrap; }
    .btn-check { background: var(--nv-green); color: #000; border: none; cursor: pointer; font-weight: 700; font-family: inherit; border-radius: 24px; }
    .btn-check:hover { background: var(--nv-green-l); }
    .btn-reveal { background: transparent; color: var(--nv-muted); border: 1px solid var(--nv-border); cursor: pointer; font-family: inherit; border-radius: 24px; }
    .btn-reveal:hover { color: var(--nv-text); border-color: rgba(255,255,255,0.25); }
    .btn-reset { background: transparent; color: var(--nv-warn); border: 1px solid var(--nv-warn); cursor: pointer; font-family: inherit; border-radius: 24px; }
    .btn-reset:hover { background: rgba(255,152,0,0.07); }
    .score-board { display: none; background: var(--nv-dark); border: 1px solid var(--nv-border); border-radius: 2px; padding: 32px; margin-top: 24px; text-align: center; }
    .score-board.show { display: block; }
    .score-circle { width: 100px; height: 100px; border-radius: 50%; background: conic-gradient(var(--nv-green) var(--score-pct, 0%), var(--nv-border) 0%); display: flex; align-items: center; justify-content: center; margin: 0 auto 16px; position: relative; }
    .score-circle::after { content: ''; position: absolute; width: 76px; height: 76px; border-radius: 50%; background: var(--nv-dark); }
    .score-num { position: relative; z-index: 1; font-size: 22px; font-weight: 800; color: var(--nv-green); }
    .score-label { font-size: 16px; font-weight: 700; color: var(--nv-white); margin-bottom: 8px; }
    .score-sub { font-size: 13px; color: var(--nv-muted); }

    /* ‚îÄ‚îÄ Full Test Page ‚îÄ‚îÄ */
    .full-test-page { padding: 52px 56px; }
    .test-selector { display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 1px; margin-bottom: 40px; background: var(--nv-border); }
    .test-card { background: #000; padding: 24px 20px; cursor: pointer; transition: background var(--transition); text-align: center; }
    .test-card:hover { background: rgba(118,185,0,0.04); }
    .test-icon { font-size: 28px; margin-bottom: 12px; }
    .test-card h3 { font-size: 13px; font-weight: 700; color: var(--nv-white); margin-bottom: 6px; }
    .test-card p { font-size: 12px; color: var(--nv-muted); }
    .test-meta { display: flex; justify-content: center; gap: 12px; margin-top: 10px; font-size: 11px; }
    .test-meta span { color: var(--nv-green); font-weight: 600; }

    /* ‚îÄ‚îÄ Footer ‚îÄ‚îÄ */
    .page-footer { padding: 36px 56px; border-top: 1px solid var(--nv-border); display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 16px; }
    .footer-nav { display: flex; gap: 12px; }
    .footer-info { font-size: 12px; color: var(--nv-muted); }

    /* ‚îÄ‚îÄ Sticky Chapter Nav ‚îÄ‚îÄ */
    .sticky-chapter-nav { position: sticky; top: var(--topbar-h); background: rgba(0,0,0,0.97); backdrop-filter: blur(12px); border-bottom: 1px solid var(--nv-border); padding: 0 56px; z-index: 800; display: flex; gap: 0; overflow-x: auto; }
    .sticky-chapter-nav::-webkit-scrollbar { height: 0; }
    .sticky-nav-item { padding: 13px 18px; font-size: 12px; font-weight: 600; color: var(--nv-muted); cursor: pointer; border-bottom: 2px solid transparent; white-space: nowrap; transition: all var(--transition); letter-spacing: 0.3px; }
    .sticky-nav-item:hover { color: var(--nv-white); }
    .sticky-nav-item.active { color: var(--nv-green); border-bottom-color: var(--nv-green); }

    /* ‚îÄ‚îÄ Responsive ‚îÄ‚îÄ */
    @media (max-width: 900px) {
      :root { --sidebar-w: 0px; }
      #sidebar { transform: translateX(-300px); width: 300px; }
      #sidebar.open { transform: translateX(0); }
      #menu-toggle { display: flex; }
      #main { margin-left: 0; }
      .chapter-page, .full-test-page { padding: 28px 20px; }
      #hero { padding: 52px 24px 48px; }
      .blueprint-grid { gap: 1px; }
      .sticky-chapter-nav { padding: 0 20px; }
      .page-footer { padding: 28px 20px; }
    }
    @media (max-width: 600px) {
      .topbar-actions .btn:not(.btn-primary) { display: none; }
      .cert-title { font-size: 13px; }
    }

  </style>
</head>
<body>

<!-- TOP BAR -->
<header id="topbar">
  <div class="brand">
    <button id="menu-toggle" onclick="toggleSidebar()" aria-label="Toggle menu">
      <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
    </button>
    <svg viewBox="0 0 200 133" xmlns="http://www.w3.org/2000/svg" aria-label="NVIDIA Logo">
      <path fill="#76b900" d="M83.3 48.7v-9.4C84.5 39.2 85.8 39 87 39c14.3 0 23.8 12.2 23.8 26.4 0 14.1-9.5 26.4-23.8 26.4-1.2 0-2.5-.2-3.7-.3V81.1c1.2.2 2.4.3 3.7.3 9.5 0 16.2-8.3 16.2-15.9 0-7.7-6.7-16-16.2-16-1.3 0-2.5.1-3.7.2zm0-26.7v9.4c-1.2-.1-2.5-.2-3.7-.2-18.8 0-33.5 15-33.5 33.8 0 18.8 14.7 33.8 33.5 33.8 1.2 0 2.5-.1 3.7-.2v9.4c-1.2.1-2.5.2-3.7.2C55.2 108.2 37 90.1 37 65c0-25.1 18.2-43.2 42.6-43.2 1.2 0 2.5.1 3.7.2zM120 39v52.8h-8.5V39H120zm22.3 0l12 38.5L166.3 39h9l-16.8 52.8h-9.4L132.3 39h10zm-95.4 0v52.8h-8.5V39h8.5z"/>
    </svg>
    <div class="brand-text">
      <span class="cert-label">NVIDIA-Certified Professional</span>
      <span class="cert-title">Agentic AI (NCP-AAI) ‚Äî Study Guide</span>
    </div>
  </div>
  <div class="topbar-actions">
    <button class="btn btn-outline btn-sm" onclick="showPage('full-test')">üìù Practice Exam</button>
    <a href="https://www.nvidia.com/en-us/learn/certification/agentic-ai-professional/" target="_blank" class="btn btn-primary btn-sm">Register for Exam ‚Üó</a>
  </div>
</header>
<div id="progress-bar"></div>

<!-- SIDEBAR -->
<nav id="sidebar">
  <div class="sidebar-header"><h3>Study Guide Navigation</h3></div>
  <div class="sidebar-search">
    <input type="text" id="sidebar-search" placeholder="üîç Search topics..." oninput="filterNav(this.value)" />
  </div>
  <div class="sidebar-nav" id="sidebar-nav">
    <div class="nav-section">
      <button class="nav-chapter-btn active" onclick="showPage('home')" data-search="home overview blueprint">
        <span class="ch-num">‚åÇ</span><span>Overview &amp; Blueprint</span>
      </button>
    </div>
    <div class="nav-divider"></div>
    <div class="nav-section" id="nav-ch1">
      <button class="nav-chapter-btn" onclick="toggleChapter(1); showPage('ch1')" data-search="agent architecture design react multi-agent memory knowledge graph">
        <span class="ch-num">1</span><span>Agent Architecture &amp; Design</span><span class="ch-weight">15%</span>
      </button>
      <div class="nav-sub" id="nav-sub-1">
        <a href="#" onclick="showPage('ch1'); scrollToSection('concepts-1'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch1'); scrollToSection('subtopics-1'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch1'); scrollToSection('frameworks-1'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch1'); scrollToSection('code-1'); return false;">Code Examples</a>
        <a href="#" onclick="showPage('ch1'); scrollToSection('practice-1'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch2">
      <button class="nav-chapter-btn" onclick="toggleChapter(2); showPage('ch2')" data-search="agent development prompts multimodal tools apis error handling streaming">
        <span class="ch-num">2</span><span>Agent Development</span><span class="ch-weight">15%</span>
      </button>
      <div class="nav-sub" id="nav-sub-2">
        <a href="#" onclick="showPage('ch2'); scrollToSection('concepts-2'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch2'); scrollToSection('subtopics-2'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch2'); scrollToSection('frameworks-2'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch2'); scrollToSection('code-2'); return false;">Code Examples</a>
        <a href="#" onclick="showPage('ch2'); scrollToSection('practice-2'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch3">
      <button class="nav-chapter-btn" onclick="toggleChapter(3); showPage('ch3')" data-search="evaluation tuning benchmarks ragas metrics aiq llm judge">
        <span class="ch-num">3</span><span>Evaluation &amp; Tuning</span><span class="ch-weight">13%</span>
      </button>
      <div class="nav-sub" id="nav-sub-3">
        <a href="#" onclick="showPage('ch3'); scrollToSection('concepts-3'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch3'); scrollToSection('subtopics-3'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch3'); scrollToSection('frameworks-3'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch3'); scrollToSection('practice-3'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch4">
      <button class="nav-chapter-btn" onclick="toggleChapter(4); showPage('ch4')" data-search="deployment scaling kubernetes docker mlops cicd canary blue-green">
        <span class="ch-num">4</span><span>Deployment &amp; Scaling</span><span class="ch-weight">13%</span>
      </button>
      <div class="nav-sub" id="nav-sub-4">
        <a href="#" onclick="showPage('ch4'); scrollToSection('concepts-4'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch4'); scrollToSection('subtopics-4'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch4'); scrollToSection('frameworks-4'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch4'); scrollToSection('practice-4'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch5">
      <button class="nav-chapter-btn" onclick="toggleChapter(5); showPage('ch5')" data-search="cognition planning memory chain-of-thought tree-of-thought reasoning self-reflection">
        <span class="ch-num">5</span><span>Cognition, Planning &amp; Memory</span><span class="ch-weight">10%</span>
      </button>
      <div class="nav-sub" id="nav-sub-5">
        <a href="#" onclick="showPage('ch5'); scrollToSection('concepts-5'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch5'); scrollToSection('subtopics-5'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch5'); scrollToSection('frameworks-5'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch5'); scrollToSection('practice-5'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch6">
      <button class="nav-chapter-btn" onclick="toggleChapter(6); showPage('ch6')" data-search="knowledge integration rag vector database etl embeddings hybrid search reranking">
        <span class="ch-num">6</span><span>Knowledge Integration &amp; Data</span><span class="ch-weight">10%</span>
      </button>
      <div class="nav-sub" id="nav-sub-6">
        <a href="#" onclick="showPage('ch6'); scrollToSection('concepts-6'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch6'); scrollToSection('subtopics-6'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch6'); scrollToSection('frameworks-6'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch6'); scrollToSection('practice-6'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch7">
      <button class="nav-chapter-btn" onclick="toggleChapter(7); showPage('ch7')" data-search="nvidia nim nemo tensorrt triton platform aiq guardrails blueprints">
        <span class="ch-num">7</span><span>NVIDIA Platform Implementation</span><span class="ch-weight">7%</span>
      </button>
      <div class="nav-sub" id="nav-sub-7">
        <a href="#" onclick="showPage('ch7'); scrollToSection('concepts-7'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch7'); scrollToSection('subtopics-7'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch7'); scrollToSection('frameworks-7'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch7'); scrollToSection('practice-7'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch8">
      <button class="nav-chapter-btn" onclick="toggleChapter(8); showPage('ch8')" data-search="monitoring logging maintenance observability metrics traces drift alerting">
        <span class="ch-num">8</span><span>Run, Monitor &amp; Maintain</span><span class="ch-weight">5%</span>
      </button>
      <div class="nav-sub" id="nav-sub-8">
        <a href="#" onclick="showPage('ch8'); scrollToSection('concepts-8'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch8'); scrollToSection('subtopics-8'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch8'); scrollToSection('frameworks-8'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch8'); scrollToSection('practice-8'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch9">
      <button class="nav-chapter-btn" onclick="toggleChapter(9); showPage('ch9')" data-search="safety ethics compliance guardrails bias privacy gdpr eu ai act prompt injection">
        <span class="ch-num">9</span><span>Safety, Ethics &amp; Compliance</span><span class="ch-weight">5%</span>
      </button>
      <div class="nav-sub" id="nav-sub-9">
        <a href="#" onclick="showPage('ch9'); scrollToSection('concepts-9'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch9'); scrollToSection('subtopics-9'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch9'); scrollToSection('frameworks-9'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch9'); scrollToSection('practice-9'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-section" id="nav-ch10">
      <button class="nav-chapter-btn" onclick="toggleChapter(10); showPage('ch10')" data-search="human ai interaction oversight hitl transparency explainability automation bias">
        <span class="ch-num">10</span><span>Human-AI Interaction &amp; Oversight</span><span class="ch-weight">5%</span>
      </button>
      <div class="nav-sub" id="nav-sub-10">
        <a href="#" onclick="showPage('ch10'); scrollToSection('concepts-10'); return false;">Key Concepts</a>
        <a href="#" onclick="showPage('ch10'); scrollToSection('subtopics-10'); return false;">Subtopics</a>
        <a href="#" onclick="showPage('ch10'); scrollToSection('frameworks-10'); return false;">Frameworks</a>
        <a href="#" onclick="showPage('ch10'); scrollToSection('practice-10'); return false;">Practice Test</a>
      </div>
    </div>
    <div class="nav-divider"></div>
    <div class="nav-section">
      <button class="nav-special-btn" onclick="showPage('full-test')">
        <span>üìù</span><span>Full Practice Exam (50 Qs)</span>
      </button>
    </div>
  </div>
</nav>

<!-- MAIN CONTENT -->
<main id="main">

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê HOME PAGE ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <div id="page-home" class="page active">
    <section id="hero">
      <div class="hero-badge">
        <svg width="14" height="14" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"/></svg>
        NVIDIA-Certified Professional
      </div>
      <h1>Agentic AI <span>(NCP-AAI)</span><br/>Complete Study Guide</h1>
      <p>A comprehensive, chapter-by-chapter study guide covering all 10 exam domains ‚Äî with key concepts, frameworks, code examples, and 100+ interactive practice questions aligned to the official NVIDIA exam blueprint.</p>
      <div class="hero-stats">
        <div class="hero-stat"><div class="stat-val">10</div><div class="stat-lbl">Exam Domains</div></div>
        <div class="hero-stat"><div class="stat-val">100+</div><div class="stat-lbl">Practice Questions</div></div>
        <div class="hero-stat"><div class="stat-val">120</div><div class="stat-lbl">Min Exam Duration</div></div>
        <div class="hero-stat"><div class="stat-val">60‚Äì70</div><div class="stat-lbl">Exam Questions</div></div>
        <div class="hero-stat"><div class="stat-val">$200</div><div class="stat-lbl">Exam Price (USD)</div></div>
      </div>
      <div class="hero-actions">
        <button class="btn btn-primary" onclick="showPage('ch1')">Start Studying ‚Üí</button>
        <button class="btn btn-outline" onclick="showPage('full-test')">Take Practice Exam</button>
        <a href="https://www.nvidia.com/en-us/learn/certification/agentic-ai-professional/" target="_blank" class="btn btn-outline">Official NVIDIA Page ‚Üó</a>
      </div>
    </section>

    <div style="padding: 40px 48px 0;">
      <h2 style="font-size:22px; font-weight:800; color:var(--nv-white); margin-bottom:6px;">Exam Blueprint</h2>
      <p style="color:var(--nv-muted); font-size:14px;">Click any domain card to jump directly to that chapter's study materials and practice test.</p>
    </div>
    <div class="blueprint-grid">
      <div class="blueprint-card" onclick="showPage('ch1')"><div class="card-header"><span class="ch-badge">Chapter 1</span><span class="weight-badge">15%</span></div><h3>Agent Architecture &amp; Design</h3><p>Foundational structuring of agentic AI systems ‚Äî how agents interact, reason, and communicate within their environments.</p><div class="card-footer">‚Üí ReAct, Multi-Agent, Knowledge Graphs, A2A</div></div>
      <div class="blueprint-card" onclick="showPage('ch2')"><div class="card-header"><span class="ch-badge">Chapter 2</span><span class="weight-badge">15%</span></div><h3>Agent Development</h3><p>Practical building, integration, and enhancement of agents ‚Äî prompts, multimodal models, tools, and error handling.</p><div class="card-footer">‚Üí Prompt Engineering, Tool Integration, Streaming</div></div>
      <div class="blueprint-card" onclick="showPage('ch3')"><div class="card-header"><span class="ch-badge">Chapter 3</span><span class="weight-badge">13%</span></div><h3>Evaluation &amp; Tuning</h3><p>Measuring, comparing, and optimizing agent performance ‚Äî benchmarks, feedback loops, and parameter tuning.</p><div class="card-footer">‚Üí RAGAS, AIQ Toolkit, LLM-as-a-Judge, Fine-tuning</div></div>
      <div class="blueprint-card" onclick="showPage('ch4')"><div class="card-header"><span class="ch-badge">Chapter 4</span><span class="weight-badge">13%</span></div><h3>Deployment &amp; Scaling</h3><p>Operationalizing and scaling agentic systems ‚Äî MLOps, CI/CD, Kubernetes, Docker, and load balancing.</p><div class="card-footer">‚Üí Kubernetes, Docker, MLOps, CI/CD, NIM</div></div>
      <div class="blueprint-card" onclick="showPage('ch5')"><div class="card-header"><span class="ch-badge">Chapter 5</span><span class="weight-badge">10%</span></div><h3>Cognition, Planning &amp; Memory</h3><p>Core cognitive processes ‚Äî reasoning strategies, chain-of-thought, task decomposition, and memory management.</p><div class="card-footer">‚Üí CoT, ToT, Plan-and-Execute, Self-Reflection</div></div>
      <div class="blueprint-card" onclick="showPage('ch6')"><div class="card-header"><span class="ch-badge">Chapter 6</span><span class="weight-badge">10%</span></div><h3>Knowledge Integration &amp; Data</h3><p>Integration of external knowledge and management of diverse data types ‚Äî RAG, vector databases, ETL pipelines.</p><div class="card-footer">‚Üí RAG, Vector DBs, Hybrid Search, ETL</div></div>
      <div class="blueprint-card" onclick="showPage('ch7')"><div class="card-header"><span class="ch-badge">Chapter 7</span><span class="weight-badge">7%</span></div><h3>NVIDIA Platform Implementation</h3><p>Leveraging NVIDIA's AI hardware and software platforms ‚Äî NIM, NeMo, TensorRT-LLM, and Triton.</p><div class="card-footer">‚Üí NIM, NeMo, TensorRT-LLM, Triton, AIQ</div></div>
      <div class="blueprint-card" onclick="showPage('ch8')"><div class="card-header"><span class="ch-badge">Chapter 8</span><span class="weight-badge">5%</span></div><h3>Run, Monitor &amp; Maintain</h3><p>Ongoing operation, monitoring, and maintenance of agentic systems post-deployment.</p><div class="card-footer">‚Üí Observability, Drift Detection, Feedback Loops</div></div>
      <div class="blueprint-card" onclick="showPage('ch9')"><div class="card-header"><span class="ch-badge">Chapter 9</span><span class="weight-badge">5%</span></div><h3>Safety, Ethics &amp; Compliance</h3><p>Responsible AI ‚Äî guardrails, bias mitigation, privacy, audit trails, and regulatory compliance.</p><div class="card-footer">‚Üí NeMo Guardrails, Bias, GDPR, EU AI Act</div></div>
      <div class="blueprint-card" onclick="showPage('ch10')"><div class="card-header"><span class="ch-badge">Chapter 10</span><span class="weight-badge">5%</span></div><h3>Human-AI Interaction &amp; Oversight</h3><p>Design of systems facilitating effective human oversight ‚Äî HITL, transparency, and explainability.</p><div class="card-footer">‚Üí HITL, Explainability, Automation Bias, Tiered Autonomy</div></div>
    </div>

    <div style="padding: 0 48px 16px;">
      <h2 style="font-size:22px; font-weight:800; color:var(--nv-white); margin-bottom:16px;">Official NVIDIA Training Courses</h2>
      <div style="display:grid; grid-template-columns:repeat(auto-fill,minmax(280px,1fr)); gap:14px; margin-bottom:40px;">
        <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div><div class="resource-title">Building RAG Agents With LLMs</div><div class="resource-type">Self-Paced ¬∑ 8 hrs ¬∑ $90 ¬∑ Course Certificate</div></div></div>
        <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div><div class="resource-title">Building Agentic AI Applications With LLMs</div><div class="resource-type">Self-Paced + ILT ¬∑ 8 hrs ¬∑ $90 ¬∑ Course Certificate</div></div></div>
        <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div><div class="resource-title">Evaluating RAG and Semantic Search Systems</div><div class="resource-type">Self-Paced ¬∑ 3 hrs ¬∑ $30</div></div></div>
        <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div><div class="resource-title">Adding New Knowledge to LLMs</div><div class="resource-type">Instructor-Led ¬∑ 8 hrs ¬∑ $500 ¬∑ Course Certificate</div></div></div>
        <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div><div class="resource-title">Introduction to Deploying RAG Pipelines for Production at Scale</div><div class="resource-type">Self-Paced + ILT ¬∑ 8 hrs ¬∑ $90 ¬∑ Course Certificate</div></div></div>
        <div class="resource-card"><div class="resource-icon external">üîó</div><div><div class="resource-title">NVIDIA NCP-AAI Certification Page</div><div class="resource-type">nvidia.com/en-us/learn/certification/agentic-ai-professional</div></div></div>
      </div>
    </div>
  </div>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CHAPTER 1 ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <div id="page-ch1" class="page">
    <div class="sticky-chapter-nav">
      <span class="sticky-nav-item active" onclick="scrollToSection('concepts-1')">Key Concepts</span>
      <span class="sticky-nav-item" onclick="scrollToSection('subtopics-1')">Subtopics</span>
      <span class="sticky-nav-item" onclick="scrollToSection('frameworks-1')">Frameworks</span>
      <span class="sticky-nav-item" onclick="scrollToSection('code-1')">Code Examples</span>
      <span class="sticky-nav-item" onclick="scrollToSection('resources-1')">Resources</span>
      <span class="sticky-nav-item" onclick="scrollToSection('practice-1')">Practice Test</span>
    </div>
    <div class="chapter-page">
      <div class="chapter-header">
        <div class="ch-meta"><span class="tag tag-green">Chapter 1</span><span class="tag tag-green">15% of Exam</span><span class="tag tag-blue">Agent Architecture</span></div>
        <h1>Agent Architecture &amp; Design</h1>
        <p class="ch-desc">Foundational structuring and design of agentic AI systems, focusing on how agents interact, reason, and communicate within their environments. This is one of the two highest-weighted domains on the exam.</p>
      </div>
      <div class="callout callout-tip"><span class="callout-icon">üí°</span><div class="callout-content"><strong>Exam Focus:</strong> This domain tests your ability to design complete agent architectures. Expect scenario-based questions about choosing between reactive, deliberative, and hybrid agent designs, configuring multi-agent communication protocols, and managing different types of memory.</div></div>

      <div class="content-section" id="concepts-1">
        <h2><span class="section-icon">üß†</span> Key Concepts</h2>
        <div class="concept-grid">
          <div class="concept-card"><div class="concept-name">Agentic AI</div><div class="concept-def">AI systems designed to autonomously make decisions and act, pursuing complex goals with limited human supervision. Agents perceive their environment, reason, plan, and execute actions.</div></div>
          <div class="concept-card"><div class="concept-name">ReAct Framework</div><div class="concept-def">Reasoning + Acting: a paradigm that interleaves verbal reasoning traces with actions. The agent generates a Thought, takes an Action, receives an Observation, and repeats until the task is complete.</div></div>
          <div class="concept-card"><div class="concept-name">Agent-to-Agent (A2A) Protocol</div><div class="concept-def">A standardized communication protocol enabling AI agents to securely exchange information, coordinate tasks, and collaborate across different frameworks and platforms.</div></div>
          <div class="concept-card"><div class="concept-name">Model Context Protocol (MCP)</div><div class="concept-def">A universal, open standard for connecting AI agents to data sources and tools, providing a standardized interface that replaces custom integrations.</div></div>
          <div class="concept-card"><div class="concept-name">Short-Term Memory (STM)</div><div class="concept-def">Handles the immediate conversational context within the LLM's context window, enabling coherent responses within a session. Limited by context window size.</div></div>
          <div class="concept-card"><div class="concept-name">Long-Term Memory (LTM)</div><div class="concept-def">Retains and recalls relevant information across extended periods via external storage (vector databases, key-value stores), enabling learning and adaptation across sessions.</div></div>
          <div class="concept-card"><div class="concept-name">Multi-Agent Orchestration</div><div class="concept-def">Coordination of multiple specialized AI agents working collaboratively to achieve a larger objective by decomposing it into sub-tasks with defined communication flows.</div></div>
          <div class="concept-card"><div class="concept-name">Knowledge Graphs</div><div class="concept-def">Structured representations of information that allow agents to understand relationships between entities, enabling relational reasoning and more accurate information retrieval.</div></div>
          <div class="concept-card"><div class="concept-name">Prompt Chains</div><div class="concept-def">Sequences of interconnected prompts where the output of one serves as input for the next, enabling complex multi-step reasoning and task execution.</div></div>
          <div class="concept-card"><div class="concept-name">Reactive Agents</div><div class="concept-def">Simple agents that respond directly to environmental stimuli without internal state or planning. Fast but limited to predefined stimulus-response mappings.</div></div>
          <div class="concept-card"><div class="concept-name">Deliberative Agents</div><div class="concept-def">Agents that maintain an internal world model and use it for planning and reasoning before acting. More capable but computationally expensive.</div></div>
          <div class="concept-card"><div class="concept-name">Hybrid Agents</div><div class="concept-def">Combine reactive and deliberative approaches ‚Äî reactive layers handle immediate responses while deliberative layers handle complex planning, balancing speed and capability.</div></div>
        </div>
      </div>

      <div class="content-section" id="subtopics-1">
        <h2><span class="section-icon">üìã</span> Official Exam Subtopics</h2>
        <ul class="subtopics-list">
          <li><span class="subtopic-num">1.1</span><div class="subtopic-content"><div class="subtopic-title">Design user interfaces for intuitive human-agent interaction</div><div class="subtopic-desc">Creating effective interfaces that facilitate seamless communication between humans and AI agents. Key considerations include transparency of agent reasoning, control mechanisms for human oversight, clear feedback loops, and building user trust. Interfaces must expose agent state and allow intervention.</div></div></li>
          <li><span class="subtopic-num">1.2</span><div class="subtopic-content"><div class="subtopic-title">Implement reasoning and action frameworks (e.g., ReAct)</div><div class="subtopic-desc">ReAct frameworks enable agents to combine reasoning (internal thought processes) with external actions (tool use or API calls) in an interleaved manner. The agent generates a Thought, takes an Action, receives an Observation, and repeats until the task is complete.</div></div></li>
          <li><span class="subtopic-num">1.3</span><div class="subtopic-content"><div class="subtopic-title">Configure agent-to-agent communication protocols for collaboration</div><div class="subtopic-desc">Establishing robust communication protocols is crucial for multi-agent systems. Protocols like A2A and MCP ensure secure, interoperable, and efficient interaction between diverse agents running on different frameworks.</div></div></li>
          <li><span class="subtopic-num">1.4</span><div class="subtopic-content"><div class="subtopic-title">Manage short-term and long-term memory for context retention</div><div class="subtopic-desc">Short-term memory handles immediate conversational context within the LLM's context window. Long-term memory uses external storage (vector databases, key-value stores) to persist information across sessions, enabling learning and adaptation.</div></div></li>
          <li><span class="subtopic-num">1.5</span><div class="subtopic-content"><div class="subtopic-title">Orchestrate multi-agent workflows and coordination</div><div class="subtopic-desc">Coordinating the activities of multiple specialized agents to achieve a common goal. Orchestration patterns include hierarchical (supervisor-worker), peer-to-peer, and pipeline architectures. LangGraph and AutoGen are key frameworks.</div></div></li>
          <li><span class="subtopic-num">1.6</span><div class="subtopic-content"><div class="subtopic-title">Apply logic trees, prompt chains, and stateful orchestration</div><div class="subtopic-desc">Logic trees provide structured decision-making paths. Prompt chains guide LLMs through complex tasks by breaking them into sequential steps. Stateful orchestration maintains context and progress across steps, enabling complex multi-turn tasks.</div></div></li>
          <li><span class="subtopic-num">1.7</span><div class="subtopic-content"><div class="subtopic-title">Integrate knowledge graphs to enable relational reasoning</div><div class="subtopic-desc">Knowledge graphs provide structured, interconnected repositories of facts and relationships. Integration allows agents to understand context, perform complex relational reasoning, and retrieve relevant information more accurately than pure vector search.</div></div></li>
          <li><span class="subtopic-num">1.8</span><div class="subtopic-content"><div class="subtopic-title">Ensure adaptability and scalability of the agent's architecture</div><div class="subtopic-desc">Agentic AI systems must adapt to new information, changing environments, and evolving user needs. Design patterns include modular agent components, horizontal scaling via containerization, and dynamic resource allocation.</div></div></li>
        </ul>
      </div>

      <div class="content-section" id="frameworks-1">
        <h2><span class="section-icon">üîß</span> Frameworks, Tools &amp; Patterns</h2>
        <table class="frameworks-table">
          <thead><tr><th>Framework / Tool</th><th>Purpose</th><th>Key Feature</th></tr></thead>
          <tbody>
            <tr><td><strong>LangGraph</strong></td><td>Multi-agent orchestration with stateful graphs</td><td>Cyclic graphs, state management, human-in-the-loop</td></tr>
            <tr><td><strong>AutoGen</strong></td><td>Conversational multi-agent framework</td><td>Dynamic agent conversations, code execution</td></tr>
            <tr><td><strong>CrewAI</strong></td><td>Role-based multi-agent collaboration</td><td>Agent roles, tasks, and crew orchestration</td></tr>
            <tr><td><strong>ReAct Pattern</strong></td><td>Reasoning + Acting loop</td><td>Thought ‚Üí Action ‚Üí Observation cycle</td></tr>
            <tr><td><strong>A2A Protocol</strong></td><td>Agent-to-agent communication standard</td><td>Secure, interoperable cross-framework messaging</td></tr>
            <tr><td><strong>MCP (Model Context Protocol)</strong></td><td>Standardized tool/context access</td><td>Universal interface for tools and data sources</td></tr>
            <tr><td><strong>LangChain</strong></td><td>LLM application framework</td><td>Chains, agents, memory, tools integration</td></tr>
            <tr><td><strong>Neo4j / cuGraph</strong></td><td>Knowledge graph storage and querying</td><td>Graph traversal, relationship reasoning</td></tr>
          </tbody>
        </table>
        <div class="arch-diagram">
          <svg viewBox="0 0 700 280" xmlns="http://www.w3.org/2000/svg" style="max-width:100%">
            <rect width="700" height="280" fill="#1a1a1a" rx="8"/>
            <text x="350" y="28" text-anchor="middle" fill="#76b900" font-size="13" font-weight="bold" font-family="sans-serif">Multi-Agent Orchestration Architecture</text>
            <rect x="270" y="45" width="160" height="50" rx="8" fill="#2d2d2d" stroke="#76b900" stroke-width="2"/>
            <text x="350" y="65" text-anchor="middle" fill="#76b900" font-size="12" font-weight="bold" font-family="sans-serif">Orchestrator Agent</text>
            <text x="350" y="83" text-anchor="middle" fill="#9e9e9e" font-size="10" font-family="sans-serif">LangGraph / AutoGen</text>
            <rect x="55" y="155" width="130" height="50" rx="8" fill="#2d2d2d" stroke="#00b4d8" stroke-width="1.5"/>
            <text x="120" y="175" text-anchor="middle" fill="#00b4d8" font-size="11" font-weight="bold" font-family="sans-serif">Research Agent</text>
            <text x="120" y="193" text-anchor="middle" fill="#9e9e9e" font-size="9" font-family="sans-serif">RAG + Web Search</text>
            <rect x="215" y="155" width="130" height="50" rx="8" fill="#2d2d2d" stroke="#00b4d8" stroke-width="1.5"/>
            <text x="280" y="175" text-anchor="middle" fill="#00b4d8" font-size="11" font-weight="bold" font-family="sans-serif">Code Agent</text>
            <text x="280" y="193" text-anchor="middle" fill="#9e9e9e" font-size="9" font-family="sans-serif">Code Gen + Exec</text>
            <rect x="375" y="155" width="130" height="50" rx="8" fill="#2d2d2d" stroke="#00b4d8" stroke-width="1.5"/>
            <text x="440" y="175" text-anchor="middle" fill="#00b4d8" font-size="11" font-weight="bold" font-family="sans-serif">Analysis Agent</text>
            <text x="440" y="193" text-anchor="middle" fill="#9e9e9e" font-size="9" font-family="sans-serif">Data + Reasoning</text>
            <rect x="535" y="155" width="130" height="50" rx="8" fill="#2d2d2d" stroke="#00b4d8" stroke-width="1.5"/>
            <text x="600" y="175" text-anchor="middle" fill="#00b4d8" font-size="11" font-weight="bold" font-family="sans-serif">Output Agent</text>
            <text x="600" y="193" text-anchor="middle" fill="#9e9e9e" font-size="9" font-family="sans-serif">Format + Deliver</text>
            <line x1="350" y1="95" x2="120" y2="155" stroke="#76b900" stroke-width="1.5" stroke-dasharray="4,3"/>
            <line x1="350" y1="95" x2="280" y2="155" stroke="#76b900" stroke-width="1.5" stroke-dasharray="4,3"/>
            <line x1="350" y1="95" x2="440" y2="155" stroke="#76b900" stroke-width="1.5" stroke-dasharray="4,3"/>
            <line x1="350" y1="95" x2="600" y2="155" stroke="#76b900" stroke-width="1.5" stroke-dasharray="4,3"/>
            <rect x="240" y="235" width="220" height="30" rx="6" fill="#1a2a00" stroke="#76b900" stroke-width="1"/>
            <text x="350" y="255" text-anchor="middle" fill="#76b900" font-size="11" font-family="sans-serif">Shared Memory / State Store</text>
          </svg>
        </div>
      </div>

      <div class="content-section" id="code-1">
        <h2><span class="section-icon">üíª</span> Code Example: ReAct Agent with NVIDIA NIM</h2>
        <div class="code-block">
          <div class="code-header"><span class="code-lang">Python ‚Äî LangGraph ReAct Agent with NVIDIA NIM</span></div>
          <pre><span class="kw">from</span> langgraph.prebuilt <span class="kw">import</span> create_react_agent
<span class="kw">from</span> langchain_nvidia_ai_endpoints <span class="kw">import</span> ChatNVIDIA
<span class="kw">from</span> langchain_core.tools <span class="kw">import</span> tool

<span class="cm"># Define a custom tool for the agent</span>
<span class="fn">@tool</span>
<span class="kw">def</span> <span class="fn">search_knowledge_base</span>(query: <span class="var">str</span>) -> <span class="var">str</span>:
    <span class="str">"""Search the internal knowledge base for relevant information."""</span>
    <span class="cm"># Vector DB retrieval logic here</span>
    <span class="kw">return</span> <span class="str">f"Results for: {query}"</span>

<span class="fn">@tool</span>
<span class="kw">def</span> <span class="fn">calculate</span>(expression: <span class="var">str</span>) -> <span class="var">str</span>:
    <span class="str">"""Evaluate a mathematical expression."""</span>
    <span class="kw">return</span> <span class="var">str</span>(<span class="fn">eval</span>(expression))

<span class="cm"># Initialize NVIDIA NIM model (OpenAI-compatible API)</span>
<span class="var">model</span> = ChatNVIDIA(
    model=<span class="str">"meta/llama-3.1-70b-instruct"</span>,
    base_url=<span class="str">"https://integrate.api.nvidia.com/v1"</span>
)

<span class="cm"># Create ReAct agent with tools ‚Äî Thought ‚Üí Action ‚Üí Observation loop</span>
<span class="var">tools</span> = [search_knowledge_base, calculate]
<span class="var">agent</span> = create_react_agent(<span class="var">model</span>, <span class="var">tools</span>)

<span class="cm"># Run the agent with a query</span>
<span class="var">result</span> = <span class="var">agent</span>.invoke({
    <span class="str">"messages"</span>: [{<span class="str">"role"</span>: <span class="str">"user"</span>, <span class="str">"content"</span>: <span class="str">"What is agentic AI?"</span>}]
})
<span class="fn">print</span>(<span class="var">result</span>[<span class="str">"messages"</span>][-<span class="num">1</span>].content)</pre>
        </div>
      </div>

      <div class="content-section" id="resources-1">
        <h2><span class="section-icon">üìö</span> Recommended Resources</h2>
        <div class="resources-grid">
          <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div class="resource-info"><div class="resource-title">Building Agentic AI Applications with LLMs</div><div class="resource-type">NVIDIA DLI Course ¬∑ Primary Recommendation</div></div></div>
          <div class="resource-card"><div class="resource-icon nvidia">üìÑ</div><div class="resource-info"><div class="resource-title">Agentic AI in the Factory ‚Äî NVIDIA Whitepaper</div><div class="resource-type">NVIDIA Documentation</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">What Are Multi-Agent Systems?</div><div class="resource-type">NVIDIA Blog</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üîó</div><div class="resource-info"><div class="resource-title">LangGraph Documentation</div><div class="resource-type">LangChain ¬∑ Framework Reference</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">ReAct: Synergizing Reasoning and Acting in LLMs</div><div class="resource-type">Google Research Blog</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">A2A Protocol ‚Äî Agent2Agent Interoperability</div><div class="resource-type">Google Developers Blog</div></div></div>
        </div>
      </div>

      <div class="practice-section" id="practice-1">
        <div class="practice-header">
          <h2>üìù Practice Test ‚Äî Chapter 1</h2>
          <div class="practice-stats"><span class="practice-stat">Questions: <span id="q-count-1">10</span></span><span class="practice-stat">Score: <span id="score-1">0/0</span></span></div>
        </div>
        <div class="quiz-controls">
          <button class="btn btn-check btn-sm" onclick="checkAll(1)">Check All Answers</button>
          <button class="btn btn-reset btn-sm" onclick="resetQuiz(1)">Reset Quiz</button>
          <button class="btn btn-reveal btn-sm" onclick="revealAll(1)">Reveal All Answers</button>
        </div>
        <div id="quiz-1"></div>
        <div class="score-board" id="score-board-1"><div class="score-circle"><span class="score-num" id="score-pct-1">0%</span></div><div class="score-label" id="score-msg-1">Complete the quiz to see your score</div><div class="score-sub" id="score-detail-1"></div></div>
      </div>
      <div class="page-footer">
        <div class="footer-info">Chapter 1 of 10 ¬∑ Agent Architecture &amp; Design ¬∑ 15% of Exam</div>
        <div class="footer-nav"><button class="btn btn-outline btn-sm" onclick="showPage('home')">‚Üê Overview</button><button class="btn btn-primary btn-sm" onclick="showPage('ch2')">Chapter 2 ‚Üí</button></div>
      </div>
    </div>
  </div>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CHAPTER 2 ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <div id="page-ch2" class="page">
    <div class="sticky-chapter-nav">
      <span class="sticky-nav-item active" onclick="scrollToSection('concepts-2')">Key Concepts</span>
      <span class="sticky-nav-item" onclick="scrollToSection('subtopics-2')">Subtopics</span>
      <span class="sticky-nav-item" onclick="scrollToSection('frameworks-2')">Frameworks</span>
      <span class="sticky-nav-item" onclick="scrollToSection('code-2')">Code Examples</span>
      <span class="sticky-nav-item" onclick="scrollToSection('resources-2')">Resources</span>
      <span class="sticky-nav-item" onclick="scrollToSection('practice-2')">Practice Test</span>
    </div>
    <div class="chapter-page">
      <div class="chapter-header">
        <div class="ch-meta"><span class="tag tag-green">Chapter 2</span><span class="tag tag-green">15% of Exam</span><span class="tag tag-blue">Agent Development</span></div>
        <h1>Agent Development</h1>
        <p class="ch-desc">Practical building, integration, and enhancement of agents ‚Äî covering prompt engineering, multimodal model integration, custom tool building, error handling patterns, and dynamic conversation flows with streaming.</p>
      </div>
      <div class="callout callout-tip"><span class="callout-icon">üí°</span><div class="callout-content"><strong>Exam Focus:</strong> Expect questions on prompt engineering best practices, how to integrate tools and APIs using function calling, error handling patterns (retry logic with exponential backoff, circuit breakers), building streaming conversation flows, and multimodal integration (text + vision + audio).</div></div>

      <div class="content-section" id="concepts-2">
        <h2><span class="section-icon">üß†</span> Key Concepts</h2>
        <div class="concept-grid">
          <div class="concept-card"><div class="concept-name">Prompt Engineering</div><div class="concept-def">The systematic design and refinement of prompts to guide AI models to generate desired outputs. Includes zero-shot, few-shot, chain-of-thought, and system prompt design techniques.</div></div>
          <div class="concept-card"><div class="concept-name">Dynamic Prompt Chains</div><div class="concept-def">Sequences of interconnected prompts where the output of one serves as input for the next, enabling complex multi-step tasks. Dynamic chains adapt based on intermediate results.</div></div>
          <div class="concept-card"><div class="concept-name">Multimodal Models</div><div class="concept-def">AI models that can process and integrate information from multiple modalities ‚Äî text, vision (images/video), and audio. Examples: GPT-4V, LLaVA, Gemini, NVIDIA's multimodal NIMs.</div></div>
          <div class="concept-card"><div class="concept-name">Function Calling</div><div class="concept-def">A mechanism allowing LLMs to output structured JSON that specifies which function to call with what arguments, enabling reliable tool use and API integration.</div></div>
          <div class="concept-card"><div class="concept-name">Retry Logic with Exponential Backoff</div><div class="concept-def">Error handling strategy that re-attempts failed operations with progressively longer wait times, preventing thundering herd problems and giving services time to recover.</div></div>
          <div class="concept-card"><div class="concept-name">Circuit Breaker Pattern</div><div class="concept-def">Prevents cascading failures by stopping requests to a failing service after a threshold of failures, allowing the system to recover gracefully before retrying.</div></div>
          <div class="concept-card"><div class="concept-name">Streaming</div><div class="concept-def">The continuous, token-by-token delivery of LLM responses, enabling real-time feedback and improved perceived performance in conversational interfaces.</div></div>
          <div class="concept-card"><div class="concept-name">Structured Output</div><div class="concept-def">Constraining LLM output to a specific format (JSON, XML) using JSON mode, grammar-constrained decoding, or Pydantic schema enforcement for reliable downstream processing.</div></div>
          <div class="concept-card"><div class="concept-name">Zero-Shot Prompting</div><div class="concept-def">Providing only a task description without examples, relying on the model's pre-trained knowledge to generate appropriate outputs.</div></div>
          <div class="concept-card"><div class="concept-name">Few-Shot Prompting</div><div class="concept-def">Including example input-output pairs in the prompt to guide the model's behavior, improving performance on specific tasks without fine-tuning.</div></div>
          <div class="concept-card"><div class="concept-name">Tool Schema</div><div class="concept-def">A formal definition of a tool including its name, description, and parameter types that the LLM uses to decide when and how to invoke the tool correctly.</div></div>
          <div class="concept-card"><div class="concept-name">Graceful Degradation</div><div class="concept-def">Designing agents to provide reduced but functional service when components fail, rather than complete failure ‚Äî ensuring user experience is maintained even during partial outages.</div></div>
        </div>
      </div>

      <div class="content-section" id="subtopics-2">
        <h2><span class="section-icon">üìã</span> Official Exam Subtopics</h2>
        <ul class="subtopics-list">
          <li><span class="subtopic-num">2.1</span><div class="subtopic-content"><div class="subtopic-title">Engineer prompts and dynamic prompt chains for reliable performance</div><div class="subtopic-desc">Effective prompt engineering involves crafting clear system prompts, using few-shot examples, and designing dynamic chains that adapt based on intermediate outputs. Techniques include role assignment, output format specification, and chain-of-thought elicitation.</div></div></li>
          <li><span class="subtopic-num">2.2</span><div class="subtopic-content"><div class="subtopic-title">Integrate generative and multimodal models (text, vision, audio)</div><div class="subtopic-desc">Modern agentic systems increasingly require processing multiple modalities. Vision models analyze images and video; audio models handle speech and sound. Integration requires understanding model APIs, handling different input formats, and combining outputs coherently.</div></div></li>
          <li><span class="subtopic-num">2.3</span><div class="subtopic-content"><div class="subtopic-title">Build and connect custom tools, APIs, and functions for external system interaction</div><div class="subtopic-desc">Custom tools extend agent capabilities to interact with external systems ‚Äî databases, REST APIs, file systems, web browsers. Tools are defined with clear schemas (name, description, parameters) that the LLM uses to decide when and how to invoke them via function calling.</div></div></li>
          <li><span class="subtopic-num">2.4</span><div class="subtopic-content"><div class="subtopic-title">Implement error handling (retry logic, graceful failure recovery)</div><div class="subtopic-desc">Production agents must handle failures gracefully. Retry logic with exponential backoff handles transient failures. Circuit breakers prevent cascading failures. Fallback strategies provide alternative responses when primary tools fail.</div></div></li>
          <li><span class="subtopic-num">2.5</span><div class="subtopic-content"><div class="subtopic-title">Develop dynamic conversation flows with real-time streaming and feedback mechanisms</div><div class="subtopic-desc">Dynamic conversation flows adapt based on user input, agent state, and task progress. Streaming delivers responses token-by-token for real-time feedback. Feedback mechanisms allow users to correct agent behavior, improving performance through human-in-the-loop interactions.</div></div></li>
          <li><span class="subtopic-num">2.6</span><div class="subtopic-content"><div class="subtopic-title">Evaluate and refine agent decision-making strategies</div><div class="subtopic-desc">Continuous evaluation of agent decisions is essential for improvement. This involves analyzing decision traces, identifying failure modes, testing alternative strategies, and iteratively refining prompts, tools, and orchestration logic based on observed performance.</div></div></li>
        </ul>
      </div>

      <div class="content-section" id="frameworks-2">
        <h2><span class="section-icon">üîß</span> Frameworks, Tools &amp; Patterns</h2>
        <table class="frameworks-table">
          <thead><tr><th>Tool / Pattern</th><th>Purpose</th><th>Key Feature</th></tr></thead>
          <tbody>
            <tr><td><strong>LangChain</strong></td><td>LLM application framework</td><td>Tool integration, chains, structured output</td></tr>
            <tr><td><strong>NVIDIA NIM</strong></td><td>Optimized model inference microservices</td><td>OpenAI-compatible API, GPU-optimized</td></tr>
            <tr><td><strong>Pydantic</strong></td><td>Data validation and structured output</td><td>Schema enforcement for LLM outputs</td></tr>
            <tr><td><strong>Gradio / Streamlit</strong></td><td>Rapid UI development for agents</td><td>Chat interfaces, streaming support</td></tr>
            <tr><td><strong>Retry Pattern</strong></td><td>Transient failure recovery</td><td>Exponential backoff with jitter</td></tr>
            <tr><td><strong>Circuit Breaker</strong></td><td>Cascading failure prevention</td><td>Open/closed/half-open states</td></tr>
            <tr><td><strong>Function Calling</strong></td><td>Structured tool invocation</td><td>JSON schema, reliable tool use</td></tr>
            <tr><td><strong>LangServe</strong></td><td>Deploy LangChain apps as REST APIs</td><td>FastAPI-based, streaming, playground</td></tr>
          </tbody>
        </table>
      </div>

      <div class="content-section" id="code-2">
        <h2><span class="section-icon">üíª</span> Code Example: Tool Integration with Error Handling &amp; Streaming</h2>
        <div class="code-block">
          <div class="code-header"><span class="code-lang">Python ‚Äî Tool with Retry Logic + Streaming</span></div>
          <pre><span class="kw">import</span> time
<span class="kw">from</span> langchain_core.tools <span class="kw">import</span> tool
<span class="kw">from</span> langchain_nvidia_ai_endpoints <span class="kw">import</span> ChatNVIDIA
<span class="kw">from</span> pydantic <span class="kw">import</span> BaseModel

<span class="cm"># Structured output schema using Pydantic</span>
<span class="kw">class</span> <span class="fn">SearchResult</span>(BaseModel):
    answer: <span class="var">str</span>
    confidence: <span class="var">float</span>
    sources: <span class="var">list</span>[<span class="var">str</span>]

<span class="cm"># Tool with exponential backoff retry logic</span>
<span class="fn">@tool</span>
<span class="kw">def</span> <span class="fn">web_search</span>(query: <span class="var">str</span>) -> <span class="var">str</span>:
    <span class="str">"""Search the web for current information about the given query."""</span>
    max_retries = <span class="num">3</span>
    <span class="kw">for</span> attempt <span class="kw">in</span> <span class="fn">range</span>(max_retries):
        <span class="kw">try</span>:
            <span class="kw">return</span> <span class="fn">_call_search_api</span>(query)  <span class="cm"># API call</span>
        <span class="kw">except</span> <span class="fn">Exception</span> <span class="kw">as</span> e:
            <span class="kw">if</span> attempt == max_retries - <span class="num">1</span>:
                <span class="kw">return</span> <span class="str">f"Search unavailable: {e}"</span>  <span class="cm"># Graceful degradation</span>
            time.sleep(<span class="num">2</span> ** attempt)  <span class="cm"># Exponential backoff: 1s, 2s, 4s</span>

<span class="cm"># Initialize NVIDIA NIM model</span>
<span class="var">model</span> = ChatNVIDIA(model=<span class="str">"meta/llama-3.1-70b-instruct"</span>)

<span class="cm"># Streaming response ‚Äî token-by-token delivery</span>
<span class="fn">print</span>(<span class="str">"Agent: "</span>, end=<span class="str">""</span>)
<span class="kw">for</span> chunk <span class="kw">in</span> <span class="var">model</span>.stream(<span class="str">"Explain agentic AI in 3 sentences"</span>):
    <span class="fn">print</span>(chunk.content, end=<span class="str">""</span>, flush=<span class="var">True</span>)

<span class="cm"># Structured output with Pydantic schema enforcement</span>
<span class="var">structured_model</span> = <span class="var">model</span>.with_structured_output(<span class="fn">SearchResult</span>)
<span class="var">result</span> = <span class="var">structured_model</span>.invoke(<span class="str">"What is RAG?"</span>)
<span class="fn">print</span>(<span class="var">result</span>.confidence)  <span class="cm"># Reliable JSON output</span></pre>
        </div>
      </div>

      <div class="content-section" id="resources-2">
        <h2><span class="section-icon">üìö</span> Recommended Resources</h2>
        <div class="resources-grid">
          <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div class="resource-info"><div class="resource-title">Building RAG Agents With LLMs</div><div class="resource-type">NVIDIA DLI Course ¬∑ Primary</div></div></div>
          <div class="resource-card"><div class="resource-icon nvidia">üéì</div><div class="resource-info"><div class="resource-title">Building Agentic AI Applications With LLMs</div><div class="resource-type">NVIDIA DLI Course ¬∑ Primary</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">NVIDIA Agent Intelligence Toolkit (AIQ)</div><div class="resource-type">NVIDIA Documentation</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">Circuit Breaker Pattern</div><div class="resource-type">Microsoft Azure Architecture Center</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">Building Multimodal AI RAG With LlamaIndex &amp; NVIDIA NIM</div><div class="resource-type">NVIDIA Developer Blog</div></div></div>
          <div class="resource-card"><div class="resource-icon external">üìÑ</div><div class="resource-info"><div class="resource-title">Prompt Engineering Guide</div><div class="resource-type">promptingguide.ai</div></div></div>
        </div>
      </div>

      <div class="practice-section" id="practice-2">
        <div class="practice-header">
          <h2>üìù Practice Test ‚Äî Chapter 2</h2>
          <div class="practice-stats"><span class="practice-stat">Questions: <span id="q-count-2">10</span></span><span class="practice-stat">Score: <span id="score-2">0/0</span></span></div>
        </div>
        <div class="quiz-controls">
          <button class="btn btn-check btn-sm" onclick="checkAll(2)">Check All Answers</button>
          <button class="btn btn-reset btn-sm" onclick="resetQuiz(2)">Reset Quiz</button>
          <button class="btn btn-reveal btn-sm" onclick="revealAll(2)">Reveal All Answers</button>
        </div>
        <div id="quiz-2"></div>
        <div class="score-board" id="score-board-2"><div class="score-circle"><span class="score-num" id="score-pct-2">0%</span></div><div class="score-label" id="score-msg-2">Complete the quiz to see your score</div><div class="score-sub" id="score-detail-2"></div></div>
      </div>
      <div class="page-footer">
        <div class="footer-info">Chapter 2 of 10 ¬∑ Agent Development ¬∑ 15% of Exam</div>
        <div class="footer-nav"><button class="btn btn-outline btn-sm" onclick="showPage('ch1')">‚Üê Chapter 1</button><button class="btn btn-primary btn-sm" onclick="showPage('ch3')">Chapter 3 ‚Üí</button></div>
      </div>
    </div>
  </div>

  <!-- Chapters 3-10: rendered dynamically by JavaScript -->
  <div id="page-ch3" class="page"><div id="ch3-content"></div></div>
  <div id="page-ch4" class="page"><div id="ch4-content"></div></div>
  <div id="page-ch5" class="page"><div id="ch5-content"></div></div>
  <div id="page-ch6" class="page"><div id="ch6-content"></div></div>
  <div id="page-ch7" class="page"><div id="ch7-content"></div></div>
  <div id="page-ch8" class="page"><div id="ch8-content"></div></div>
  <div id="page-ch9" class="page"><div id="ch9-content"></div></div>
  <div id="page-ch10" class="page"><div id="ch10-content"></div></div>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê FULL PRACTICE EXAM ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <div id="page-full-test" class="page">
    <div class="full-test-page">
      <div class="chapter-header">
        <div class="ch-meta"><span class="tag tag-blue">Practice Exam</span><span class="tag tag-warn">All 10 Domains</span></div>
        <h1>Full Practice Exam</h1>
        <p class="ch-desc">Simulate the real NCP-AAI exam experience. Select a domain-specific test or take the full mixed exam covering all 10 domains proportionally weighted.</p>
      </div>
      <div class="callout callout-info"><span class="callout-icon">‚ÑπÔ∏è</span><div class="callout-content"><strong>Real Exam Format:</strong> The NCP-AAI exam has 60‚Äì70 questions, 120-minute time limit, and is proctored remotely via Certiverse. The exam costs $200 USD. A passing score is required ‚Äî NVIDIA does not publicly disclose the exact passing threshold. The mixed exam below contains 50 questions (5 per chapter).</div></div>

      <h2 style="font-size:19px; font-weight:700; color:var(--nv-white); margin-bottom:16px;">Chapter-Specific Practice Tests</h2>
      <div class="test-selector">
        <div class="test-card" onclick="showPage('ch1'); setTimeout(()=>scrollToSection('practice-1'),300)"><div class="test-icon">üèóÔ∏è</div><h3>Agent Architecture &amp; Design</h3><p>Chapter 1</p><div class="test-meta"><span>10 Qs</span><span>15%</span></div></div>
        <div class="test-card" onclick="showPage('ch2'); setTimeout(()=>scrollToSection('practice-2'),300)"><div class="test-icon">‚öôÔ∏è</div><h3>Agent Development</h3><p>Chapter 2</p><div class="test-meta"><span>10 Qs</span><span>15%</span></div></div>
        <div class="test-card" onclick="showPage('ch3'); setTimeout(()=>scrollToSection('practice-3'),300)"><div class="test-icon">üìä</div><h3>Evaluation &amp; Tuning</h3><p>Chapter 3</p><div class="test-meta"><span>10 Qs</span><span>13%</span></div></div>
        <div class="test-card" onclick="showPage('ch4'); setTimeout(()=>scrollToSection('practice-4'),300)"><div class="test-icon">üöÄ</div><h3>Deployment &amp; Scaling</h3><p>Chapter 4</p><div class="test-meta"><span>10 Qs</span><span>13%</span></div></div>
        <div class="test-card" onclick="showPage('ch5'); setTimeout(()=>scrollToSection('practice-5'),300)"><div class="test-icon">üß©</div><h3>Cognition, Planning &amp; Memory</h3><p>Chapter 5</p><div class="test-meta"><span>10 Qs</span><span>10%</span></div></div>
        <div class="test-card" onclick="showPage('ch6'); setTimeout(()=>scrollToSection('practice-6'),300)"><div class="test-icon">üóÑÔ∏è</div><h3>Knowledge Integration &amp; Data</h3><p>Chapter 6</p><div class="test-meta"><span>10 Qs</span><span>10%</span></div></div>
        <div class="test-card" onclick="showPage('ch7'); setTimeout(()=>scrollToSection('practice-7'),300)"><div class="test-icon">üñ•Ô∏è</div><h3>NVIDIA Platform Implementation</h3><p>Chapter 7</p><div class="test-meta"><span>10 Qs</span><span>7%</span></div></div>
        <div class="test-card" onclick="showPage('ch8'); setTimeout(()=>scrollToSection('practice-8'),300)"><div class="test-icon">üì°</div><h3>Run, Monitor &amp; Maintain</h3><p>Chapter 8</p><div class="test-meta"><span>10 Qs</span><span>5%</span></div></div>
        <div class="test-card" onclick="showPage('ch9'); setTimeout(()=>scrollToSection('practice-9'),300)"><div class="test-icon">üõ°Ô∏è</div><h3>Safety, Ethics &amp; Compliance</h3><p>Chapter 9</p><div class="test-meta"><span>10 Qs</span><span>5%</span></div></div>
        <div class="test-card" onclick="showPage('ch10'); setTimeout(()=>scrollToSection('practice-10'),300)"><div class="test-icon">üë•</div><h3>Human-AI Interaction &amp; Oversight</h3><p>Chapter 10</p><div class="test-meta"><span>10 Qs</span><span>5%</span></div></div>
      </div>

      <h2 style="font-size:19px; font-weight:700; color:var(--nv-white); margin-bottom:16px; margin-top:40px;">Mixed Full Practice Exam (All 10 Domains)</h2>
      <div class="practice-section">
        <div class="practice-header">
          <h2>üìù Full Mixed Exam ‚Äî 50 Questions</h2>
          <div class="practice-stats"><span class="practice-stat">Questions: <span>50</span></span><span class="practice-stat">Score: <span id="score-full">0/0</span></span></div>
        </div>
        <div class="quiz-controls">
          <button class="btn btn-check btn-sm" onclick="checkAll('full')">Check All Answers</button>
          <button class="btn btn-reset btn-sm" onclick="resetQuiz('full')">Reset Exam</button>
          <button class="btn btn-reveal btn-sm" onclick="revealAll('full')">Reveal All Answers</button>
        </div>
        <div id="quiz-full"></div>
        <div class="score-board" id="score-board-full"><div class="score-circle"><span class="score-num" id="score-pct-full">0%</span></div><div class="score-label" id="score-msg-full">Complete the exam to see your score</div><div class="score-sub" id="score-detail-full"></div></div>
      </div>
    </div>
  </div>

</main>

<!-- Load data and app scripts -->
<script>
// NCP-AAI Study Guide ‚Äî Quiz Data for all 10 chapters
const QUIZ_DATA = {
  1: [
    { q: "Which of the following best describes the primary purpose of the ReAct reasoning framework in agentic AI systems?", opts: ["To enable agents to generate creative text and images","To combine internal reasoning with external actions for dynamic problem-solving","To manage the long-term memory of an AI agent","To facilitate secure communication between different AI agents"], ans: 1, exp: "ReAct (Reasoning + Acting) interleaves verbal reasoning traces with actions, allowing agents to dynamically plan, execute, and adapt strategies. The agent generates a Thought, takes an Action, receives an Observation, and repeats." },
    { q: "What is a key benefit of implementing Agent-to-Agent (A2A) communication protocols in a multi-agent system?", opts: ["It reduces the computational resources required for individual agents","It allows agents to operate entirely independently without any coordination","It ensures secure and interoperable exchange of information and coordination of actions","It primarily focuses on improving the human-agent interaction interface"], ans: 2, exp: "A2A protocols ensure secure, interoperable, and efficient interaction between diverse agents running on different frameworks and platforms, enabling true multi-agent collaboration." },
    { q: "An AI agent needs to remember the immediate context of a conversation to respond coherently. Which type of memory is primarily responsible for this function?", opts: ["Long-Term Memory","Episodic Memory","Short-Term Memory","Semantic Memory"], ans: 2, exp: "Short-Term Memory (STM) handles the immediate conversational context within the LLM's context window, enabling coherent responses within a session." },
    { q: "In the context of multi-agent systems, what does orchestration refer to?", opts: ["The process of an individual agent learning new skills","The coordination of multiple agents to achieve a common goal","The method of storing historical data for future reference","The design of the agent's internal reasoning mechanisms"], ans: 1, exp: "Orchestration involves coordinating the activities of multiple specialized agents to achieve a common goal, ensuring tasks are distributed appropriately and agents work together efficiently." },
    { q: "Which component is essential for an AI agent to integrate external knowledge and understand relationships between different pieces of information?", opts: ["Prompt Chains","Logic Trees","Knowledge Graphs","Short-Term Memory"], ans: 2, exp: "Knowledge Graphs provide structured, interconnected repositories of facts and relationships, enabling agents to understand context, perform relational reasoning, and retrieve accurate information." },
    { q: "When designing user interfaces for human-agent interaction, which principle is crucial for building user trust and enabling effective oversight?", opts: ["Minimizing human intervention to maximize agent autonomy","Providing transparency into the agent's reasoning and decision-making process","Limiting the agent's ability to learn from user feedback","Relying solely on visual cues for agent communication"], ans: 1, exp: "Transparency of agent reasoning is crucial for building trust. Users need to understand why an agent made a decision to trust it and provide meaningful oversight." },
    { q: "What is the primary benefit of using prompt chains in agentic AI systems?", opts: ["To reduce the computational cost of running LLMs","To enable LLMs to process information in parallel","To guide LLMs through multi-step tasks by breaking them into manageable steps","To replace the need for external tools in agent operations"], ans: 2, exp: "Prompt chains guide LLMs through complex tasks by breaking them into sequential, manageable steps, ensuring coherent and targeted responses at each stage." },
    { q: "An agentic AI system needs to handle a significant increase in user requests without performance degradation. This requirement primarily relates to which aspect of agent design?", opts: ["Adaptability","Scalability","Interpretability","Robustness"], ans: 1, exp: "Scalability ensures that the agentic AI system can efficiently handle increased workloads and expand its capabilities without significant performance degradation." },
    { q: "Which framework is specifically designed for building stateful multi-agent systems with cyclic graphs and human-in-the-loop capabilities?", opts: ["LangChain","CrewAI","LangGraph","AutoGen"], ans: 2, exp: "LangGraph is specifically designed for building stateful, multi-actor applications with LLMs using graph-based orchestration, supporting cyclic workflows and human-in-the-loop interactions." },
    { q: "In a hybrid agent architecture, what is the primary role of the reactive layer?", opts: ["To perform long-term planning and goal management","To handle immediate, time-sensitive responses to environmental stimuli","To manage long-term memory and knowledge storage","To coordinate communication between multiple agents"], ans: 1, exp: "In hybrid architectures, the reactive layer handles immediate, time-sensitive responses to environmental stimuli without deliberation, while the deliberative layer handles complex planning." }
  ],
  2: [
    { q: "Which technique is most effective for ensuring an LLM produces output in a specific JSON format for downstream processing?", opts: ["Zero-shot prompting","Few-shot prompting with examples","Structured output / JSON mode with schema enforcement","Chain-of-thought prompting"], ans: 2, exp: "Structured output with schema enforcement (e.g., Pydantic models, JSON mode) reliably constrains LLM output to a specific format, ensuring compatibility with downstream systems." },
    { q: "When implementing retry logic for a tool that calls an external API, what is the recommended approach to avoid overwhelming the failing service?", opts: ["Retry immediately with the same parameters","Use exponential backoff with jitter","Retry with a fixed 1-second delay","Only retry once before failing permanently"], ans: 1, exp: "Exponential backoff with jitter progressively increases wait time between retries while adding randomness, preventing thundering herd problems and giving the service time to recover." },
    { q: "An agent needs to process both text queries and images from users. Which type of model should be integrated?", opts: ["A text-only language model","A multimodal model that handles both text and vision inputs","Two separate models ‚Äî one for text and one for images","A speech recognition model"], ans: 1, exp: "Multimodal models can process multiple input types (text, images, audio) in a unified model, enabling agents to understand and respond to diverse input formats." },
    { q: "What is the primary purpose of function calling in LLM-based agents?", opts: ["To execute Python code directly within the LLM","To allow the LLM to output structured JSON specifying which tool to invoke with what arguments","To stream responses token-by-token to the user","To compress the context window for efficiency"], ans: 1, exp: "Function calling allows LLMs to output structured JSON specifying which function/tool to call with what arguments, enabling reliable, schema-validated tool use." },
    { q: "Which pattern prevents cascading failures in a distributed agentic system by stopping requests to a failing service after a threshold?", opts: ["Retry Pattern","Bulkhead Pattern","Circuit Breaker Pattern","Timeout Pattern"], ans: 2, exp: "The Circuit Breaker Pattern prevents cascading failures by monitoring failure rates and 'opening' the circuit (stopping requests) when failures exceed a threshold, allowing the system to recover." },
    { q: "When building a conversational agent with streaming responses, what is the primary benefit of token-by-token streaming?", opts: ["It reduces the total number of tokens generated","It improves perceived performance and enables real-time feedback","It reduces GPU memory usage during inference","It improves the accuracy of the generated responses"], ans: 1, exp: "Streaming delivers responses token-by-token, significantly improving perceived performance and user experience by showing partial results immediately rather than waiting for the complete response." },
    { q: "A developer wants to create a tool that allows an agent to query a SQL database. What is the most important consideration when defining this tool?", opts: ["Maximizing the number of database tables accessible","Providing a clear schema with name, description, and parameter types","Using the fastest possible query execution method","Storing all query results in the agent's context window"], ans: 1, exp: "A clear tool schema (name, description, parameter types) is essential because the LLM uses this information to decide when and how to invoke the tool correctly." },
    { q: "What is the key difference between zero-shot and few-shot prompting?", opts: ["Zero-shot uses more tokens than few-shot","Few-shot includes example input-output pairs in the prompt; zero-shot does not","Zero-shot is only for classification tasks","Few-shot requires fine-tuning the model"], ans: 1, exp: "Few-shot prompting includes example input-output pairs in the prompt to guide the model's behavior, while zero-shot relies solely on the task description without examples." },
    { q: "When integrating an audio model into an agentic system, which capability does it primarily add?", opts: ["Visual scene understanding","Speech-to-text transcription and audio analysis","Code generation and execution","Database query optimization"], ans: 1, exp: "Audio models primarily add speech-to-text transcription and audio analysis capabilities, enabling agents to process spoken language and audio signals as inputs." },
    { q: "Which approach best ensures an agent's decision-making strategy is continuously improved in production?", opts: ["Retraining the base LLM weekly","Collecting structured user feedback and analyzing decision traces for iterative refinement","Increasing the model's parameter count","Reducing the number of tools available to the agent"], ans: 1, exp: "Continuous improvement requires collecting structured user feedback, analyzing decision traces to identify failure modes, and iteratively refining prompts, tools, and orchestration logic." }
  ],
  3: [
    { q: "Which RAGAS metric specifically measures whether the generated answer is supported by the retrieved context?", opts: ["Answer Relevancy","Faithfulness","Context Recall","Context Precision"], ans: 1, exp: "Faithfulness measures whether the generated answer is factually consistent with and supported by the retrieved context, detecting hallucinations in RAG systems." },
    { q: "What is the primary purpose of implementing evaluation pipelines for agentic AI systems?", opts: ["To reduce the cost of running the agent","To systematically measure and compare agent performance across tasks and datasets","To increase the speed of agent responses","To simplify the agent's architecture"], ans: 1, exp: "Evaluation pipelines provide systematic, reproducible measurement of agent performance, enabling comparison across versions and identification of areas for improvement." },
    { q: "When tuning model parameters for an agent, what is the typical trade-off when increasing the temperature parameter?", opts: ["Higher temperature increases accuracy but reduces speed","Higher temperature increases creativity/diversity but may reduce factual accuracy","Higher temperature reduces memory usage","Higher temperature improves context retention"], ans: 1, exp: "Temperature controls randomness in generation. Higher values increase diversity and creativity but can lead to less factually accurate or coherent outputs." },
    { q: "The NVIDIA Agent Intelligence Toolkit (AIQ Toolkit) is primarily used for which purpose?", opts: ["Training new LLMs from scratch","Evaluating, profiling, and optimizing agentic AI workflows","Managing Kubernetes deployments","Designing user interfaces for agents"], ans: 1, exp: "The NVIDIA AIQ Toolkit is designed for evaluating, profiling, and optimizing agentic AI workflows, providing metrics and insights to improve agent performance." },
    { q: "What does 'latency-efficiency trade-off' mean in the context of agent tuning?", opts: ["Trading response quality for faster hardware","Balancing response accuracy against response speed","Trading memory usage for CPU efficiency","Balancing the number of agents against system complexity"], ans: 1, exp: "The latency-efficiency trade-off involves balancing response accuracy (which often requires larger, slower models) against response speed (which requires smaller, faster models)." },
    { q: "Which evaluation approach uses another LLM to assess the quality of an agent's responses?", opts: ["BLEU score evaluation","Human evaluation only","LLM-as-a-Judge","Unit test evaluation"], ans: 2, exp: "LLM-as-a-Judge uses a powerful LLM to evaluate the quality of another model's responses, providing scalable automated evaluation that correlates well with human judgment." },
    { q: "What is the purpose of A/B testing in the context of agentic AI evaluation?", opts: ["To test two different hardware configurations","To compare two versions of an agent to determine which performs better on defined metrics","To evaluate two different users' preferences","To test two different deployment environments"], ans: 1, exp: "A/B testing compares two versions of an agent (e.g., different prompts, models, or configurations) on the same tasks to determine which version performs better on defined metrics." },
    { q: "Which technique is used to improve a model's performance on a specific task by training it on a smaller, task-specific dataset?", opts: ["Prompt engineering","Retrieval-Augmented Generation","Fine-tuning","Quantization"], ans: 2, exp: "Fine-tuning involves training a pre-trained model on a smaller, task-specific dataset to adapt its behavior and improve performance on that specific domain or task type." },
    { q: "What does 'context precision' measure in RAG evaluation?", opts: ["The relevance of the query to the knowledge base","The proportion of retrieved context chunks that are actually relevant to the query","The speed of context retrieval","The size of the retrieved context"], ans: 1, exp: "Context Precision measures the proportion of retrieved context chunks that are actually relevant to the query, indicating how much noise is in the retrieved context." },
    { q: "In agent evaluation, what is 'trajectory evaluation'?", opts: ["Evaluating the agent's physical movement in a simulation","Assessing the sequence of actions and decisions an agent takes to complete a task","Measuring the latency of each API call","Evaluating the agent's memory usage over time"], ans: 1, exp: "Trajectory evaluation assesses the sequence of actions and decisions (the trajectory) an agent takes to complete a task, evaluating not just the final outcome but the quality of the reasoning process." }
  ],
  4: [
    { q: "Which container orchestration platform is most commonly used for deploying and scaling agentic AI systems in production?", opts: ["Docker Swarm","Apache Mesos","Kubernetes","VMware vSphere"], ans: 2, exp: "Kubernetes is the industry-standard container orchestration platform for deploying, scaling, and managing containerized applications including agentic AI systems in production." },
    { q: "What is the primary benefit of containerizing an agentic AI application with Docker?", opts: ["It automatically optimizes the model's inference speed","It ensures consistent, reproducible deployment across different environments","It provides built-in GPU acceleration","It eliminates the need for a Kubernetes cluster"], ans: 1, exp: "Docker containers package the application with all its dependencies, ensuring consistent behavior across development, testing, and production environments regardless of the underlying infrastructure." },
    { q: "In a CI/CD pipeline for agentic AI, what does the 'CD' (Continuous Deployment) component primarily handle?", opts: ["Code quality checks and unit tests","Automated deployment of validated changes to production environments","Model training and fine-tuning","User acceptance testing"], ans: 1, exp: "Continuous Deployment automates the deployment of validated changes to production environments, reducing manual intervention and enabling rapid, reliable releases of agent updates." },
    { q: "What is horizontal scaling in the context of agentic AI deployment?", opts: ["Increasing the GPU memory of a single server","Adding more instances of the agent service to distribute load","Upgrading to a faster CPU","Increasing the model's parameter count"], ans: 1, exp: "Horizontal scaling adds more instances of the service to distribute load across multiple servers, as opposed to vertical scaling which increases the resources of a single server." },
    { q: "Which NVIDIA tool is specifically designed for deploying optimized AI model inference as microservices?", opts: ["NVIDIA NeMo","NVIDIA NIM (NVIDIA Inference Microservices)","NVIDIA TensorRT","NVIDIA RAPIDS"], ans: 1, exp: "NVIDIA NIM (NVIDIA Inference Microservices) provides pre-built, optimized inference microservices for rapidly deploying AI models with GPU acceleration and OpenAI-compatible APIs." },
    { q: "What is the purpose of a load balancer in a scaled agentic AI deployment?", opts: ["To train models faster","To distribute incoming requests across multiple agent instances to prevent overload","To compress model weights for faster loading","To monitor agent performance metrics"], ans: 1, exp: "A load balancer distributes incoming requests across multiple agent instances, preventing any single instance from being overwhelmed and ensuring high availability and performance." },
    { q: "In MLOps for agentic AI, what is model versioning primarily used for?", opts: ["Reducing model file size","Tracking and managing different versions of models to enable rollback and reproducibility","Encrypting model weights","Compressing training data"], ans: 1, exp: "Model versioning tracks and manages different versions of models, enabling rollback to previous versions if issues arise, reproducibility of results, and auditability of model changes." },
    { q: "What is a Helm chart in the context of Kubernetes deployments?", opts: ["A visual dashboard for monitoring Kubernetes clusters","A package manager template that defines, installs, and upgrades Kubernetes applications","A load balancing algorithm","A GPU scheduling policy"], ans: 1, exp: "A Helm chart is a package of pre-configured Kubernetes resources that can be deployed as a unit, simplifying the deployment and management of complex applications on Kubernetes." },
    { q: "Which deployment strategy minimizes downtime by gradually shifting traffic from the old version to the new version?", opts: ["Big Bang deployment","Blue-Green deployment","Canary deployment","Rolling deployment"], ans: 2, exp: "Canary deployment gradually shifts a small percentage of traffic to the new version, allowing teams to validate the new version with real traffic before full rollout, minimizing risk and downtime." },
    { q: "What is the primary purpose of an API gateway in a microservices-based agentic AI architecture?", opts: ["To train machine learning models","To provide a single entry point for client requests, handling routing, authentication, and rate limiting","To store model weights","To perform GPU inference"], ans: 1, exp: "An API gateway provides a single entry point for all client requests, handling cross-cutting concerns like routing, authentication, rate limiting, and SSL termination for microservices." }
  ],
  5: [
    { q: "Which reasoning technique involves prompting an LLM to generate intermediate reasoning steps before producing a final answer?", opts: ["Zero-shot prompting","Chain-of-Thought (CoT) prompting","Retrieval-Augmented Generation","Few-shot prompting"], ans: 1, exp: "Chain-of-Thought (CoT) prompting encourages LLMs to generate intermediate reasoning steps ('think step by step') before producing a final answer, improving accuracy on complex reasoning tasks." },
    { q: "What is the key difference between Chain-of-Thought (CoT) and Tree-of-Thought (ToT) reasoning?", opts: ["CoT is faster than ToT","ToT explores multiple reasoning branches simultaneously, while CoT follows a single linear reasoning path","CoT requires more memory than ToT","ToT is only used for mathematical problems"], ans: 1, exp: "Tree-of-Thought explores multiple reasoning branches simultaneously (like a tree), evaluating different paths and backtracking when needed, while CoT follows a single linear reasoning path." },
    { q: "In task decomposition for agentic AI, what is the primary benefit of breaking a complex task into sub-tasks?", opts: ["It reduces the total number of LLM calls required","It allows specialized agents to handle specific sub-tasks, improving overall performance and manageability","It eliminates the need for memory management","It reduces the context window requirements"], ans: 1, exp: "Task decomposition allows specialized agents or components to handle specific sub-tasks they are optimized for, improving overall system performance, reliability, and manageability." },
    { q: "What type of memory allows an AI agent to retain information about specific past events and experiences?", opts: ["Semantic Memory","Procedural Memory","Episodic Memory","Working Memory"], ans: 2, exp: "Episodic Memory stores information about specific past events and experiences, allowing agents to recall what happened in previous interactions and learn from past successes and failures." },
    { q: "Which planning approach involves an agent creating a complete plan before taking any actions?", opts: ["Reactive Planning","Plan-and-Execute","ReAct","Dynamic Planning"], ans: 1, exp: "Plan-and-Execute is a planning approach where the agent first creates a complete plan for the entire task, then executes each step sequentially, as opposed to reactive approaches that plan one step at a time." },
    { q: "What is the primary function of working memory in an AI agent's cognitive architecture?", opts: ["Storing permanent knowledge about the world","Holding and manipulating information needed for the current task in real-time","Storing learned skills and procedures","Maintaining long-term user preferences"], ans: 1, exp: "Working memory holds and manipulates information needed for the current task in real-time, similar to human working memory ‚Äî it's the 'scratch pad' for active reasoning and problem-solving." },
    { q: "In the context of agentic AI, what is 'goal decomposition'?", opts: ["Breaking down hardware requirements for agent deployment","Breaking a high-level goal into smaller, achievable sub-goals that can be pursued sequentially or in parallel","Analyzing the agent's performance metrics","Decomposing the agent's neural network architecture"], ans: 1, exp: "Goal decomposition breaks a high-level, complex goal into smaller, achievable sub-goals that can be pursued sequentially or in parallel by specialized agents or components." },
    { q: "Which technique enables an agent to reflect on and critique its own outputs to improve them?", opts: ["Retrieval-Augmented Generation","Self-Reflection / Self-Critique","Function Calling","Prompt Chaining"], ans: 1, exp: "Self-Reflection (also called Self-Critique or Reflexion) enables agents to evaluate their own outputs, identify errors or improvements, and iteratively refine their responses without external feedback." },
    { q: "What is the primary advantage of using vector databases for long-term memory in agentic AI systems?", opts: ["They provide faster SQL query execution","They enable semantic similarity search, allowing retrieval of contextually relevant memories","They reduce the cost of storing data","They provide built-in encryption for sensitive data"], ans: 1, exp: "Vector databases enable semantic similarity search using embeddings, allowing agents to retrieve contextually relevant memories based on meaning rather than exact keyword matching." },
    { q: "In stateful agent orchestration, what does 'state' refer to?", opts: ["The physical hardware state of the server","The persistent information about the agent's current task, context, and progress that is maintained across steps","The agent's model weights","The network connection status"], ans: 1, exp: "In stateful orchestration, 'state' refers to the persistent information about the agent's current task, context, intermediate results, and progress that is maintained and updated across multiple steps." }
  ],
  6: [
    { q: "What is Retrieval-Augmented Generation (RAG) primarily designed to address?", opts: ["The high computational cost of training LLMs","The knowledge cutoff limitation of LLMs by providing access to up-to-date external information","The slow inference speed of large language models","The lack of multimodal capabilities in LLMs"], ans: 1, exp: "RAG addresses the knowledge cutoff limitation of LLMs by retrieving relevant information from external knowledge bases at inference time, enabling models to answer questions about current or domain-specific information." },
    { q: "In a RAG pipeline, what is the primary purpose of the embedding model?", opts: ["To generate the final text response","To convert text chunks into dense vector representations for similarity search","To split documents into smaller chunks","To rank retrieved results by relevance"], ans: 1, exp: "The embedding model converts text (both documents and queries) into dense vector representations (embeddings) that capture semantic meaning, enabling similarity-based retrieval in vector databases." },
    { q: "What is 'chunking' in the context of RAG document processing?", opts: ["Compressing documents to reduce storage size","Splitting large documents into smaller, manageable pieces for indexing and retrieval","Encrypting sensitive document content","Converting documents from PDF to text format"], ans: 1, exp: "Chunking splits large documents into smaller pieces (chunks) for indexing. The chunk size and overlap strategy significantly impact retrieval quality ‚Äî too large loses precision, too small loses context." },
    { q: "Which type of search combines keyword-based (BM25) and semantic (vector) search for improved retrieval accuracy?", opts: ["Fuzzy Search","Full-Text Search","Hybrid Search","Graph Search"], ans: 2, exp: "Hybrid Search combines keyword-based search (BM25/TF-IDF) with semantic vector search, leveraging the strengths of both approaches to improve retrieval accuracy and recall." },
    { q: "What is the purpose of a re-ranker in a RAG pipeline?", opts: ["To split documents into chunks","To re-order initially retrieved documents by their actual relevance to the query for improved precision","To generate the final answer","To create embeddings for new documents"], ans: 1, exp: "A re-ranker takes the initially retrieved documents and re-orders them based on a more precise relevance scoring model, improving the precision of the top results passed to the LLM." },
    { q: "Which vector database is developed by NVIDIA and optimized for GPU-accelerated similarity search?", opts: ["Pinecone","Chroma","Weaviate","Milvus with NVIDIA RAPIDS"], ans: 3, exp: "Milvus with NVIDIA RAPIDS (and NVIDIA's cuVS library) provides GPU-accelerated vector similarity search, significantly faster than CPU-based alternatives for large-scale deployments." },
    { q: "What is 'agentic RAG' as opposed to standard RAG?", opts: ["RAG that uses a larger language model","RAG where an agent dynamically decides when, what, and how to retrieve information, rather than following a fixed pipeline","RAG that only works with structured data","RAG that doesn't require a vector database"], ans: 1, exp: "Agentic RAG uses an agent to dynamically decide when to retrieve, what to retrieve, and how to use the retrieved information, enabling adaptive multi-step retrieval strategies unlike fixed RAG pipelines." },
    { q: "In data handling for agentic AI, what does an ETL pipeline stand for and what does it do?", opts: ["Evaluate-Test-Learn: a model evaluation framework","Extract-Transform-Load: a process for moving and preparing data from sources to destinations","Embed-Train-Launch: a model deployment process","Encode-Tokenize-Learn: a text preprocessing pipeline"], ans: 1, exp: "ETL (Extract-Transform-Load) is a data integration process that extracts data from source systems, transforms it into the required format, and loads it into a destination system like a vector database." },
    { q: "What is the primary challenge of handling multimodal data (text, images, tables) in RAG systems?", opts: ["Multimodal data requires more storage space","Different modalities require different embedding models and processing pipelines, making unified retrieval complex","Multimodal data is always less accurate than text-only data","Images cannot be stored in vector databases"], ans: 1, exp: "Multimodal RAG requires different embedding models for different modalities (text embeddings, image embeddings) and complex pipelines to process, index, and retrieve across modalities coherently." },
    { q: "What is 'knowledge graph RAG' and what advantage does it offer over standard vector RAG?", opts: ["It uses a larger vector database","It combines graph-based relational reasoning with vector search, enabling multi-hop reasoning across connected entities","It is faster than standard RAG","It requires less storage space"], ans: 1, exp: "Knowledge Graph RAG combines graph traversal with vector search, enabling multi-hop reasoning across connected entities ‚Äî answering questions that require understanding relationships between multiple facts." }
  ],
  7: [
    { q: "What is NVIDIA NIM (NVIDIA Inference Microservices) primarily designed for?", opts: ["Training large language models from scratch","Providing pre-built, optimized inference microservices for deploying AI models with GPU acceleration","Managing Kubernetes clusters","Monitoring AI model performance in production"], ans: 1, exp: "NVIDIA NIM provides pre-built, GPU-optimized inference microservices with OpenAI-compatible APIs, enabling rapid deployment of AI models without requiring deep infrastructure expertise." },
    { q: "Which NVIDIA platform is specifically designed for building, customizing, and deploying enterprise-grade AI models and agents?", opts: ["NVIDIA RAPIDS","NVIDIA NeMo","NVIDIA CUDA","NVIDIA TensorRT"], ans: 1, exp: "NVIDIA NeMo is an end-to-end platform for building, customizing, and deploying enterprise-grade generative AI models and agentic AI applications, including tools for training, fine-tuning, and guardrails." },
    { q: "What is the primary purpose of TensorRT-LLM in the NVIDIA AI stack?", opts: ["To provide a user interface for model management","To optimize and accelerate LLM inference on NVIDIA GPUs through techniques like quantization and kernel fusion","To train LLMs from scratch","To manage multi-GPU distributed training"], ans: 1, exp: "TensorRT-LLM optimizes and accelerates LLM inference on NVIDIA GPUs using techniques like quantization, kernel fusion, and in-flight batching, significantly reducing latency and increasing throughput." },
    { q: "What role does NVIDIA Triton Inference Server play in a production AI deployment?", opts: ["It trains models on distributed GPU clusters","It serves as a production-grade model serving platform supporting multiple frameworks and enabling concurrent model execution","It provides a visual interface for model debugging","It manages the fine-tuning of foundation models"], ans: 1, exp: "NVIDIA Triton Inference Server is a production-grade model serving platform that supports multiple frameworks (TensorFlow, PyTorch, TensorRT), enables concurrent model execution, and provides dynamic batching." },
    { q: "What is NVIDIA NeMo Guardrails primarily used for in agentic AI systems?", opts: ["Accelerating model training","Implementing safety, compliance, and behavioral guardrails to control LLM outputs and agent behavior","Managing GPU memory allocation","Optimizing inference throughput"], ans: 1, exp: "NVIDIA NeMo Guardrails implements programmable safety and compliance guardrails that control LLM outputs and agent behavior, preventing unsafe, off-topic, or non-compliant responses." },
    { q: "Which NVIDIA tool provides a comprehensive framework for evaluating, profiling, and optimizing agentic AI workflows?", opts: ["NVIDIA NIM","NVIDIA NeMo","NVIDIA Agent Intelligence Toolkit (AIQ Toolkit)","NVIDIA TensorRT"], ans: 2, exp: "The NVIDIA Agent Intelligence Toolkit (AIQ Toolkit) provides evaluation, profiling, and optimization capabilities specifically designed for agentic AI workflows, helping developers measure and improve agent performance." },
    { q: "What is the significance of NVIDIA NIM's OpenAI-compatible API?", opts: ["It requires OpenAI's infrastructure to run","It allows developers to use existing OpenAI SDK code with NVIDIA-hosted models by simply changing the base URL","It only works with OpenAI's GPT models","It requires an OpenAI API key"], ans: 1, exp: "NVIDIA NIM's OpenAI-compatible API allows developers to switch from OpenAI to NVIDIA-hosted models by simply changing the base_url, minimizing code changes and enabling easy migration." },
    { q: "In the NVIDIA AI platform stack, what is the relationship between NIM and NeMo?", opts: ["They are competing products that do the same thing","NeMo is used for model development and customization; NIM is used for optimized production inference deployment","NIM is used for training; NeMo is used for inference","They are the same product with different names"], ans: 1, exp: "NeMo handles the model development lifecycle (training, fine-tuning, customization, guardrails), while NIM handles optimized production inference deployment ‚Äî they are complementary tools in the NVIDIA AI stack." },
    { q: "What is quantization in the context of TensorRT-LLM optimization?", opts: ["Measuring the quality of model outputs","Reducing model precision (e.g., from FP32 to INT8) to decrease memory usage and increase inference speed with minimal accuracy loss","Increasing the number of model parameters","Distributing the model across multiple GPUs"], ans: 1, exp: "Quantization reduces model precision (e.g., FP32 to INT8 or FP16) to decrease memory footprint and increase inference speed, with carefully managed accuracy trade-offs." },
    { q: "Which NVIDIA Blueprint provides a reference architecture for building production-ready RAG-based AI agents?", opts: ["NVIDIA CUDA Toolkit","NVIDIA AI Enterprise","NVIDIA NIM Agent Blueprints","NVIDIA DGX Cloud"], ans: 2, exp: "NVIDIA NIM Agent Blueprints provide reference architectures and pre-built components for building production-ready agentic AI applications, including RAG agents, customer service agents, and more." }
  ],
  8: [
    { q: "What is the primary purpose of implementing observability in a production agentic AI system?", opts: ["To reduce the cost of running the agent","To gain visibility into the agent's behavior, performance, and health through metrics, logs, and traces","To improve the agent's response quality","To manage the agent's training data"], ans: 1, exp: "Observability provides visibility into the agent's internal state and behavior through metrics (what is happening), logs (what happened), and traces (how it happened), enabling diagnosis and optimization." },
    { q: "Which three pillars form the foundation of observability in distributed AI systems?", opts: ["Training, Inference, Deployment","Metrics, Logs, Traces","CPU, Memory, Network","Accuracy, Latency, Throughput"], ans: 1, exp: "The three pillars of observability are Metrics (quantitative measurements), Logs (timestamped event records), and Traces (end-to-end request flows), providing comprehensive system visibility." },
    { q: "What is 'data drift' in the context of monitoring production AI agents?", opts: ["A bug in the data pipeline","A change in the statistical properties of input data over time that can degrade model performance","A security vulnerability in the data storage","A deliberate change to the training dataset"], ans: 1, exp: "Data drift occurs when the statistical properties of production input data change over time compared to training data, potentially degrading model performance and requiring retraining or adaptation." },
    { q: "What is the purpose of implementing alerting thresholds in AI system monitoring?", opts: ["To limit the number of user requests","To automatically notify operators when key metrics exceed acceptable bounds, enabling proactive intervention","To improve model accuracy","To reduce infrastructure costs"], ans: 1, exp: "Alerting thresholds automatically notify operators when key metrics (latency, error rate, accuracy) exceed acceptable bounds, enabling proactive intervention before issues impact users significantly." },
    { q: "Which approach is most effective for maintaining an agent's knowledge base current with new information?", opts: ["Retraining the base LLM monthly","Implementing automated ETL pipelines that continuously update the vector database with new documents","Manually updating prompts weekly","Increasing the context window size"], ans: 1, exp: "Automated ETL pipelines that continuously update the vector database with new documents ensure the agent's knowledge base remains current without requiring expensive LLM retraining." },
    { q: "What is the primary benefit of implementing distributed tracing in a multi-agent system?", opts: ["It reduces the number of API calls","It enables end-to-end visibility of request flows across multiple agents and services, facilitating debugging","It improves model accuracy","It reduces storage costs"], ans: 1, exp: "Distributed tracing tracks request flows across multiple agents and services, providing end-to-end visibility that enables debugging of complex multi-step failures in distributed agentic systems." },
    { q: "In production AI monitoring, what does 'model degradation' refer to?", opts: ["Physical damage to GPU hardware","A gradual decrease in model performance over time due to data drift, concept drift, or changing user needs","A decrease in model file size","A reduction in the number of model parameters"], ans: 1, exp: "Model degradation refers to the gradual decrease in model performance over time, often caused by data drift (input distribution changes), concept drift (relationship changes), or evolving user needs." },
    { q: "What is the purpose of a 'feedback loop' in maintaining production agentic AI systems?", opts: ["To reduce API latency","To capture user feedback and system performance data to continuously improve the agent over time","To manage GPU memory","To handle authentication"], ans: 1, exp: "A feedback loop captures user feedback and system performance data, feeding it back into the improvement cycle (retraining, prompt refinement, knowledge updates) to continuously improve the agent." },
    { q: "Which tool is commonly used for visualizing metrics and creating dashboards for AI system monitoring?", opts: ["Docker","Kubernetes","Grafana","TensorFlow"], ans: 2, exp: "Grafana is a widely-used open-source platform for creating dashboards and visualizing metrics from various data sources (Prometheus, InfluxDB), commonly used for monitoring AI system performance." },
    { q: "What is 'canary analysis' in the context of AI model updates?", opts: ["A security audit of the model","Gradually rolling out a new model version to a small subset of traffic to validate performance before full deployment","A method for training models on small datasets","A technique for compressing model weights"], ans: 1, exp: "Canary analysis involves deploying a new model version to a small percentage of traffic, monitoring its performance metrics compared to the current version before deciding to proceed with full rollout." }
  ],
  9: [
    { q: "What is the primary purpose of NVIDIA NeMo Guardrails in agentic AI systems?", opts: ["To accelerate model inference speed","To implement programmable safety and compliance guardrails that control LLM outputs and prevent unsafe behavior","To manage GPU memory allocation","To optimize training efficiency"], ans: 1, exp: "NVIDIA NeMo Guardrails implements programmable safety guardrails using Colang, a domain-specific language for defining conversation flows and safety rules that control LLM behavior." },
    { q: "Which type of AI bias occurs when a model performs differently across demographic groups due to imbalanced training data?", opts: ["Confirmation Bias","Algorithmic Bias / Representation Bias","Recency Bias","Anchoring Bias"], ans: 1, exp: "Algorithmic/Representation Bias occurs when training data underrepresents certain demographic groups, causing the model to perform differently (often worse) for those groups in production." },
    { q: "What is 'prompt injection' in the context of agentic AI security?", opts: ["A technique for improving prompt quality","A malicious attack where adversarial instructions are embedded in user input or retrieved content to hijack agent behavior","A method for compressing prompts","A technique for caching frequent prompts"], ans: 1, exp: "Prompt injection is a security attack where adversarial instructions are embedded in user input or retrieved content (indirect injection), attempting to override the agent's system prompt and hijack its behavior." },
    { q: "Which principle of responsible AI ensures that AI systems can be understood and their decisions explained to stakeholders?", opts: ["Fairness","Explainability / Interpretability","Robustness","Privacy"], ans: 1, exp: "Explainability/Interpretability ensures that AI systems' decisions and reasoning can be understood and explained to stakeholders, building trust and enabling accountability." },
    { q: "What does GDPR compliance require regarding personal data processed by AI agents in the EU?", opts: ["All personal data must be stored in the EU only","Users must have rights including access, correction, deletion, and data portability; processing must have a legal basis","AI agents cannot process any personal data","All AI models must be open-source"], ans: 1, exp: "GDPR requires that personal data processing has a legal basis, users have rights (access, correction, deletion, portability), data is minimized, and appropriate security measures are implemented." },
    { q: "What is the 'principle of least privilege' in the context of agentic AI security?", opts: ["Giving agents access to all possible tools and data sources","Granting agents only the minimum permissions necessary to perform their designated tasks","Using the smallest possible AI model","Minimizing the number of agents in a system"], ans: 1, exp: "The principle of least privilege grants agents only the minimum permissions necessary to perform their designated tasks, reducing the potential damage from compromised or misbehaving agents." },
    { q: "What is 'hallucination' in the context of LLM-based agents, and why is it a safety concern?", opts: ["A visual artifact in image generation","When an LLM generates plausible-sounding but factually incorrect information, potentially leading to harmful decisions","A memory overflow error in the model","When the model generates duplicate responses"], ans: 1, exp: "Hallucination occurs when LLMs generate plausible-sounding but factually incorrect information. In agentic systems, this is a critical safety concern as agents may take harmful actions based on false information." },
    { q: "Which approach is most effective for detecting and mitigating bias in an AI agent's outputs?", opts: ["Using a larger model","Implementing diverse evaluation datasets, bias metrics, and regular audits across demographic groups","Increasing training data volume","Using faster inference hardware"], ans: 1, exp: "Detecting and mitigating bias requires diverse evaluation datasets that represent different demographic groups, specific bias metrics, and regular audits to identify and address disparate performance." },
    { q: "What is an 'audit trail' in the context of AI compliance, and why is it important?", opts: ["A list of all models used in training","A comprehensive, tamper-evident log of all agent actions, decisions, and data accesses for accountability and regulatory compliance","A performance benchmark report","A list of approved AI vendors"], ans: 1, exp: "An audit trail is a comprehensive, tamper-evident log of all agent actions, decisions, and data accesses. It is essential for accountability, regulatory compliance, and post-incident investigation." },
    { q: "What is the EU AI Act's risk-based approach to AI regulation?", opts: ["All AI systems are treated equally regardless of their use case","AI systems are categorized by risk level (unacceptable, high, limited, minimal), with requirements proportional to risk","Only AI systems used in healthcare are regulated","AI regulation is left entirely to individual member states"], ans: 1, exp: "The EU AI Act categorizes AI systems by risk level: unacceptable risk (prohibited), high risk (strict requirements), limited risk (transparency obligations), and minimal risk (no specific requirements)." }
  ],
  10: [
    { q: "What is Human-in-the-Loop (HITL) in the context of agentic AI systems?", opts: ["A system where humans replace AI agents entirely","A design pattern where human oversight and intervention are integrated into the agent's decision-making process at critical points","A method for training models using human feedback","A user interface design principle"], ans: 1, exp: "Human-in-the-Loop (HITL) integrates human oversight and intervention into the agent's decision-making process at critical points, enabling humans to review, approve, or correct agent actions before they are executed." },
    { q: "What is 'explainability' in human-AI interaction, and why is it important?", opts: ["The ability of an AI to explain jokes","The ability to provide understandable explanations of AI decisions and reasoning to human users, building trust and enabling oversight","The speed at which an AI responds to queries","The accuracy of AI predictions"], ans: 1, exp: "Explainability provides understandable explanations of AI decisions and reasoning to human users. It is critical for building trust, enabling meaningful oversight, and satisfying regulatory requirements." },
    { q: "Which design principle helps users understand when they are interacting with an AI agent versus a human?", opts: ["Minimalism","Transparency / AI Disclosure","Gamification","Personalization"], ans: 1, exp: "Transparency/AI Disclosure ensures users know they are interacting with an AI agent, not a human. This is both an ethical principle and a legal requirement in many jurisdictions." },
    { q: "What is 'appropriate reliance' in human-AI teaming?", opts: ["Humans always overriding AI decisions","Humans calibrating their trust in AI to match the AI's actual reliability ‚Äî neither over-relying nor under-relying on AI outputs","Humans never questioning AI decisions","AI systems making all decisions without human input"], ans: 1, exp: "Appropriate reliance means humans calibrate their trust in AI to match its actual reliability ‚Äî trusting it when it is reliable and questioning it when it may be wrong, avoiding both over-reliance and under-reliance." },
    { q: "What is the purpose of 'confidence scores' or 'uncertainty indicators' in human-AI interaction?", opts: ["To measure the AI's processing speed","To communicate the AI's level of certainty about its outputs, helping humans decide when to verify or override AI decisions","To track user engagement","To measure response quality"], ans: 1, exp: "Confidence scores communicate the AI's uncertainty about its outputs, enabling humans to make informed decisions about when to trust, verify, or override AI outputs ‚Äî critical for appropriate reliance." },
    { q: "In designing human-agent interaction, what is a 'feedback mechanism' and why is it important?", opts: ["A hardware component for measuring agent performance","A channel through which users can provide corrections, ratings, or preferences that improve the agent over time","A security feature for preventing unauthorized access","A method for compressing agent responses"], ans: 1, exp: "Feedback mechanisms allow users to provide corrections, ratings, or preferences that improve the agent over time through active learning, fine-tuning, or prompt refinement ‚Äî essential for continuous improvement." },
    { q: "What is 'cognitive load' in the context of human-AI interaction design?", opts: ["The computational load on the AI model","The mental effort required by a human to understand and interact with an AI system, which should be minimized in good UX design","The memory usage of the AI agent","The number of API calls made per session"], ans: 1, exp: "Cognitive load refers to the mental effort required by humans to understand and interact with an AI system. Good human-AI interaction design minimizes unnecessary cognitive load through clear, intuitive interfaces." },
    { q: "What is 'automation bias' in human-AI teaming, and how can it be mitigated?", opts: ["A preference for automated testing","The tendency for humans to over-rely on automated AI recommendations, even when incorrect; mitigated by training, uncertainty indicators, and requiring active confirmation for high-stakes decisions","A bias in automated data collection","A preference for certain AI models over others"], ans: 1, exp: "Automation bias is the tendency to over-rely on automated AI recommendations. It is mitigated through user training, displaying uncertainty indicators, requiring active human confirmation for high-stakes decisions, and regular performance reviews." },
    { q: "Which approach best supports meaningful human oversight of autonomous AI agents in high-stakes domains?", opts: ["Giving agents full autonomy to maximize efficiency","Implementing tiered autonomy with human approval gates for high-impact actions and comprehensive audit trails","Removing all human oversight to reduce bottlenecks","Using only rule-based systems instead of AI"], ans: 1, exp: "Tiered autonomy with human approval gates for high-impact actions, combined with comprehensive audit trails, provides meaningful oversight while maintaining efficiency for routine, lower-risk agent actions." },
    { q: "What does 'shared situational awareness' mean in human-AI teaming?", opts: ["Both humans and AI using the same hardware","Both humans and the AI agent having a common, up-to-date understanding of the current task state, goals, and relevant context","Humans and AI sharing the same training data","AI agents sharing data with each other"], ans: 1, exp: "Shared situational awareness means both humans and the AI agent have a common, up-to-date understanding of the current task state, goals, constraints, and relevant context ‚Äî essential for effective collaboration." }
  ]
};

// Generate full mixed exam from all chapters (5 questions each)
QUIZ_DATA['full'] = [];
for (let ch = 1; ch <= 10; ch++) {
  const chData = QUIZ_DATA[ch];
  // Pick 5 questions from each chapter
  const selected = chData.slice(0, 5);
  selected.forEach(q => {
    QUIZ_DATA['full'].push({...q, chapter: ch});
  });
}

</script>
<script>
// NCP-AAI Study Guide ‚Äî Dynamic Chapter Data (Chapters 3‚Äì10)
// Rendered by app.js renderChapter() function

const CHAPTER_DATA = {
  3: {
    title: "Evaluation & Tuning",
    weight: "13%",
    tag: "Evaluation",
    desc: "Measuring, comparing, and optimizing agent performance ‚Äî covering benchmark datasets, RAGAS metrics, LLM-as-a-Judge, A/B testing, fine-tuning techniques, and the NVIDIA AIQ Toolkit.",
    examFocus: "Expect questions on RAGAS metrics (faithfulness, answer relevancy, context recall, context precision), the AIQ Toolkit's role, LLM-as-a-Judge methodology, LoRA fine-tuning, and how to design evaluation pipelines. Know the difference between each RAGAS metric.",
    concepts: [
      { name: "RAGAS Framework", def: "Retrieval Augmented Generation Assessment ‚Äî a framework providing metrics to evaluate RAG pipelines: Faithfulness, Answer Relevancy, Context Recall, and Context Precision." },
      { name: "Faithfulness", def: "RAGAS metric measuring whether the generated answer is factually supported by the retrieved context. Low faithfulness = hallucination." },
      { name: "Answer Relevancy", def: "RAGAS metric measuring how well the answer addresses the original question. High relevancy means the answer directly responds to what was asked." },
      { name: "Context Recall", def: "RAGAS metric measuring what fraction of ground truth information is present in the retrieved context. Low recall = retrieval is missing key information." },
      { name: "Context Precision", def: "RAGAS metric measuring the proportion of retrieved chunks that are actually relevant. Low precision = too much irrelevant context (noise) is retrieved." },
      { name: "LLM-as-a-Judge", def: "Using a powerful LLM to evaluate the quality of another LLM's outputs. Scalable automated evaluation that captures nuanced quality dimensions." },
      { name: "LoRA (Low-Rank Adaptation)", def: "Parameter-efficient fine-tuning technique that adds small trainable low-rank matrices to frozen pre-trained weights, reducing compute/memory by 10-100x vs. full fine-tuning." },
      { name: "RLHF", def: "Reinforcement Learning from Human Feedback ‚Äî fine-tuning approach using human preference data to train a reward model, then optimizing the LLM against it." },
      { name: "A/B Testing", def: "Comparing two agent versions by routing traffic to both and measuring performance metrics, enabling data-driven decisions about which configuration to deploy." },
      { name: "Trajectory Evaluation", def: "Assessing the complete sequence of actions and decisions an agent takes to complete a task, not just the final output." },
      { name: "Benchmark Datasets", def: "Standardized question sets with known correct answers for objective, reproducible evaluation. Examples: MMLU, HumanEval, domain-specific benchmarks." },
      { name: "Reward Hacking", def: "When an agent learns to maximize the reward model's score through behaviors that appear good to the reward model but don't actually align with human preferences." }
    ],
    subtopics: [
      { num: "3.1", title: "Implement evaluation pipelines for systematic performance measurement", desc: "Evaluation pipelines systematically measure agent performance across standardized datasets, enabling reproducible comparison across versions. They include data collection, metric computation, and reporting components." },
      { num: "3.2", title: "Apply RAGAS and other metrics to assess RAG pipeline quality", desc: "RAGAS provides four key metrics: Faithfulness (is the answer grounded?), Answer Relevancy (does it address the question?), Context Recall (is key info retrieved?), Context Precision (is retrieved info relevant?)." },
      { num: "3.3", title: "Use LLM-as-a-Judge for scalable automated evaluation", desc: "LLM-as-a-Judge uses a powerful LLM to evaluate outputs on dimensions like helpfulness, accuracy, and safety. It scales better than human evaluation while capturing nuanced quality aspects." },
      { num: "3.4", title: "Conduct A/B testing to compare agent configurations", desc: "A/B testing routes traffic to two agent versions simultaneously, measuring which performs better on defined KPIs. Essential for data-driven decisions about prompt changes, model upgrades, or configuration updates." },
      { num: "3.5", title: "Apply fine-tuning techniques (LoRA, RLHF) for performance improvement", desc: "LoRA enables efficient fine-tuning with minimal compute. RLHF aligns model behavior with human preferences. Both adapt pre-trained models for specific domains or tasks." },
      { num: "3.6", title: "Profile and optimize agent workflows using the NVIDIA AIQ Toolkit", desc: "The AIQ Toolkit profiles agent execution to identify bottlenecks, measure component latency, and compare configurations. It integrates with NVIDIA's NIM and NeMo ecosystem." }
    ],
    frameworks: [
      { name: "RAGAS", purpose: "RAG pipeline evaluation framework", feature: "Faithfulness, Relevancy, Recall, Precision metrics" },
      { name: "NVIDIA AIQ Toolkit", purpose: "Agent workflow evaluation and profiling", feature: "Performance profiling, bottleneck identification" },
      { name: "LangSmith", purpose: "LLM application tracing and evaluation", feature: "Trace visualization, dataset management, evaluators" },
      { name: "Weights & Biases", purpose: "ML experiment tracking and evaluation", feature: "Run comparison, metric visualization, model registry" },
      { name: "LoRA / QLoRA", purpose: "Parameter-efficient fine-tuning", feature: "Low-rank adaptation, 10-100x compute reduction" },
      { name: "NVIDIA NeMo", purpose: "LLM training and fine-tuning framework", feature: "Distributed training, LoRA, P-tuning, SFT" },
      { name: "DeepEval", purpose: "LLM evaluation framework", feature: "RAGAS metrics, custom evaluators, CI integration" },
      { name: "Arize Phoenix", purpose: "LLM observability and evaluation", feature: "Trace analysis, evaluation datasets, drift detection" }
    ],
    resources: [
      { icon: "üéì", type: "nvidia", title: "Evaluating RAG and Semantic Search Systems", sub: "NVIDIA DLI Course ¬∑ 3 hrs ¬∑ $30" },
      { icon: "üéì", type: "nvidia", title: "Building Agentic AI Applications with LLMs", sub: "NVIDIA DLI Course ¬∑ Primary" },
      { icon: "üìÑ", type: "external", title: "RAGAS Documentation", sub: "docs.ragas.io ¬∑ Framework Reference" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA AIQ Toolkit Documentation", sub: "NVIDIA Developer Docs" },
      { icon: "üìÑ", type: "external", title: "LoRA: Low-Rank Adaptation of Large Language Models", sub: "Microsoft Research Paper" },
      { icon: "üìÑ", type: "external", title: "Judging LLM-as-a-Judge with MT-Bench", sub: "LMSYS Research Paper" }
    ]
  },

  4: {
    title: "Deployment & Scaling",
    weight: "13%",
    tag: "MLOps",
    desc: "Operationalizing and scaling agentic AI systems ‚Äî covering containerization with Docker, orchestration with Kubernetes, CI/CD pipelines, deployment strategies, MLOps practices, and NVIDIA NIM deployment.",
    examFocus: "Focus on deployment strategies (canary, blue-green, rolling, shadow), Kubernetes concepts (HPA, services, deployments), CI/CD for AI, infrastructure as code, and model drift. Know when to use each deployment strategy and the trade-offs involved.",
    concepts: [
      { name: "Canary Deployment", def: "Routes a small percentage of traffic to a new version while keeping the old version running, allowing gradual validation with limited blast radius." },
      { name: "Blue-Green Deployment", def: "Maintains two identical environments (blue=current, green=new). Traffic switches instantly between them, enabling zero-downtime deployments and immediate rollback." },
      { name: "Rolling Deployment", def: "Gradually replaces old instances with new ones (e.g., one at a time), maintaining availability throughout but with mixed versions during transition." },
      { name: "Shadow Deployment", def: "Runs new version in parallel with production, receiving the same traffic but not serving responses to users ‚Äî ideal for validation without user impact." },
      { name: "Horizontal Pod Autoscaler (HPA)", def: "Kubernetes resource that automatically scales pod replicas based on CPU, memory, or custom metrics, handling variable load efficiently." },
      { name: "Infrastructure as Code (IaC)", def: "Managing infrastructure through version-controlled configuration files (Terraform, Helm, Kubernetes YAML) rather than manual processes." },
      { name: "CI/CD Pipeline", def: "Continuous Integration/Continuous Deployment ‚Äî automated pipelines that test, validate, and deploy code changes, ensuring quality and enabling rapid iteration." },
      { name: "Model Drift", def: "Degradation of model performance as real-world data distribution shifts away from the training distribution over time." },
      { name: "NVIDIA NIM", def: "Containerized, GPU-optimized inference microservices with OpenAI-compatible APIs, deployable on any NVIDIA GPU infrastructure." },
      { name: "Load Balancing", def: "Distributing incoming requests across multiple service instances to prevent overload, improve availability, and maximize throughput." },
      { name: "Health Checks", def: "Periodic probes (liveness, readiness) that Kubernetes uses to determine if a pod is running correctly and ready to receive traffic." },
      { name: "Feature Flags", def: "Configuration toggles that enable/disable features in production without code deployment, enabling gradual rollouts and instant rollback." }
    ],
    subtopics: [
      { num: "4.1", title: "Containerize agent services using Docker for portability and consistency", desc: "Docker packages agents with all dependencies into portable containers, ensuring consistent behavior across dev, staging, and production environments." },
      { num: "4.2", title: "Orchestrate containers with Kubernetes for scaling and resilience", desc: "Kubernetes manages container lifecycle, auto-scaling (HPA), load balancing, health checks, and rolling updates for production-grade agentic deployments." },
      { num: "4.3", title: "Implement CI/CD pipelines for automated testing and deployment", desc: "CI/CD pipelines automate testing (unit, integration, evaluation benchmarks) and deployment, catching regressions early and enabling rapid, reliable iteration." },
      { num: "4.4", title: "Apply deployment strategies (canary, blue-green, rolling) for safe releases", desc: "Different strategies balance risk vs. speed: canary for gradual validation, blue-green for instant rollback, rolling for zero-downtime updates, shadow for risk-free testing." },
      { num: "4.5", title: "Manage model versioning and rollback capabilities", desc: "Version control for model artifacts, configurations, and prompts enables rollback when new versions degrade performance and provides audit trails for compliance." },
      { num: "4.6", title: "Monitor and address model drift in production", desc: "Continuous monitoring of input statistics and output quality detects drift early. Responses include knowledge base updates, prompt adjustments, or model retraining." }
    ],
    frameworks: [
      { name: "Docker", purpose: "Container runtime and image management", feature: "Environment consistency, portability, isolation" },
      { name: "Kubernetes", purpose: "Container orchestration platform", feature: "Auto-scaling, self-healing, load balancing" },
      { name: "Helm", purpose: "Kubernetes package manager", feature: "Templated deployments, versioned releases" },
      { name: "NVIDIA NIM", purpose: "GPU-optimized inference microservices", feature: "OpenAI-compatible API, TensorRT-LLM optimized" },
      { name: "GitHub Actions / GitLab CI", purpose: "CI/CD pipeline automation", feature: "Automated testing, deployment triggers" },
      { name: "Terraform", purpose: "Infrastructure as Code", feature: "Multi-cloud provisioning, state management" },
      { name: "Prometheus + Grafana", purpose: "Metrics collection and visualization", feature: "Custom dashboards, alerting rules" },
      { name: "Argo CD", purpose: "GitOps continuous delivery for Kubernetes", feature: "Declarative deployments, drift detection" }
    ],
    resources: [
      { icon: "üéì", type: "nvidia", title: "Introduction to Deploying RAG Pipelines for Production at Scale", sub: "NVIDIA DLI Course ¬∑ 8 hrs" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA NIM Deployment Guide", sub: "NVIDIA Developer Documentation" },
      { icon: "üìÑ", type: "external", title: "Kubernetes Documentation", sub: "kubernetes.io ¬∑ Official Reference" },
      { icon: "üìÑ", type: "external", title: "MLOps Principles", sub: "ml-ops.org ¬∑ Best Practices" },
      { icon: "üìÑ", type: "external", title: "The Twelve-Factor App", sub: "12factor.net ¬∑ Cloud-native principles" },
      { icon: "üìÑ", type: "external", title: "Canary Deployments with Kubernetes", sub: "Google Cloud Architecture Center" }
    ]
  },

  5: {
    title: "Cognition, Planning & Memory",
    weight: "10%",
    tag: "Reasoning",
    desc: "Core cognitive processes enabling sophisticated agentic behavior ‚Äî reasoning strategies, chain-of-thought, tree of thoughts, task decomposition, planning patterns, and memory management across different memory types.",
    examFocus: "Know the differences between CoT, ToT, ReAct, and Plan-and-Execute. Understand the four memory types (semantic, episodic, procedural, working) and their use cases. Be able to identify which reasoning strategy is most appropriate for different task types.",
    concepts: [
      { name: "Chain-of-Thought (CoT)", def: "Prompting technique that instructs the model to show intermediate reasoning steps before the final answer, improving accuracy on complex reasoning tasks." },
      { name: "Tree of Thoughts (ToT)", def: "Explores multiple reasoning paths simultaneously in a tree structure, evaluating each branch before committing ‚Äî analogous to human deliberation." },
      { name: "Plan-and-Execute", def: "Two-phase pattern: Planner decomposes the goal into sub-tasks; Executor carries out each sub-task. Allows replanning if execution fails." },
      { name: "Self-Reflection / Reflexion", def: "Agent evaluates its own previous outputs, identifies errors, and uses this critique to improve subsequent attempts without human feedback." },
      { name: "Semantic Memory", def: "Stores factual knowledge and general world knowledge not tied to specific experiences. Implemented via vector databases or model pre-training." },
      { name: "Episodic Memory", def: "Records specific past experiences and interactions, enabling recall of what happened in previous sessions for personalization and learning." },
      { name: "Procedural Memory", def: "Stores knowledge of how to perform tasks ‚Äî step-by-step procedures, skills, and workflows. Enables reuse of successful strategies." },
      { name: "Working Memory", def: "The active context currently being processed ‚Äî the LLM's context window. Limited capacity requiring management strategies." },
      { name: "Task Decomposition", def: "Breaking complex goals into smaller, manageable sub-tasks that can be executed sequentially or in parallel." },
      { name: "Scratchpad", def: "Temporary workspace in the context window where the agent records intermediate reasoning, calculations, and partial results." },
      { name: "Memory Compression", def: "Summarizing older conversation history to free context window space while preserving key information for continued coherent interaction." },
      { name: "MCTS (Monte Carlo Tree Search)", def: "Search algorithm used in ToT-style reasoning to systematically explore and evaluate multiple solution paths using simulation and backpropagation." }
    ],
    subtopics: [
      { num: "5.1", title: "Apply reasoning strategies (CoT, ToT, ReAct) for complex problem-solving", desc: "Different reasoning strategies suit different task types: CoT for linear reasoning, ToT for exploratory problems, ReAct for tasks requiring external information, Plan-and-Execute for long-horizon tasks." },
      { num: "5.2", title: "Implement task decomposition and hierarchical planning", desc: "Breaking complex goals into sub-tasks enables tackling problems too complex for single-step solutions. Hierarchical planning organizes sub-tasks into structured execution plans." },
      { num: "5.3", title: "Manage different memory types for context retention and learning", desc: "Effective memory management combines working memory (context window), semantic memory (knowledge base), episodic memory (past interactions), and procedural memory (task workflows)." },
      { num: "5.4", title: "Implement self-reflection and iterative improvement mechanisms", desc: "Self-reflection enables agents to critique their own outputs and improve without human feedback. Reflexion frameworks formalize this into structured self-critique and revision cycles." },
      { num: "5.5", title: "Handle context window limitations with memory management strategies", desc: "Strategies include: conversation summarization, sliding window approaches, selective memory retrieval, and external long-term memory stores to manage context window constraints." }
    ],
    frameworks: [
      { name: "LangGraph", purpose: "Stateful multi-agent orchestration", feature: "Cyclic graphs, memory state management" },
      { name: "Reflexion", purpose: "Self-reflection and iterative improvement", feature: "Verbal reinforcement learning, self-critique" },
      { name: "Tree of Thoughts", purpose: "Multi-path reasoning exploration", feature: "Branch generation, evaluation, pruning" },
      { name: "MemGPT", purpose: "Extended context memory management", feature: "Virtual context window, memory tiers" },
      { name: "Zep / Mem0", purpose: "Long-term memory for LLM applications", feature: "Persistent memory, semantic search" },
      { name: "LangChain Memory", purpose: "Conversation memory management", feature: "Buffer, summary, vector store memory" },
      { name: "Plan-and-Execute", purpose: "Long-horizon task planning", feature: "Planner-Executor separation, replanning" },
      { name: "AutoGen", purpose: "Multi-agent conversation framework", feature: "Agent conversations, code execution, memory" }
    ],
    resources: [
      { icon: "üéì", type: "nvidia", title: "Building Agentic AI Applications with LLMs", sub: "NVIDIA DLI Course ¬∑ Primary" },
      { icon: "üìÑ", type: "external", title: "Chain-of-Thought Prompting Elicits Reasoning in LLMs", sub: "Google Research Paper" },
      { icon: "üìÑ", type: "external", title: "Tree of Thoughts: Deliberate Problem Solving with LLMs", sub: "Princeton / Google Research" },
      { icon: "üìÑ", type: "external", title: "Reflexion: Language Agents with Verbal Reinforcement Learning", sub: "Northeastern / MIT Research" },
      { icon: "üìÑ", type: "external", title: "A Survey on Memory Mechanisms for LLM-based Agents", sub: "arXiv Survey Paper" },
      { icon: "üìÑ", type: "external", title: "ReAct: Synergizing Reasoning and Acting in LLMs", sub: "Google Research" }
    ]
  },

  6: {
    title: "Knowledge Integration & Data",
    weight: "10%",
    tag: "RAG & Data",
    desc: "Integration of external knowledge and management of diverse data types ‚Äî RAG pipelines, vector databases, embedding models, hybrid search, ETL pipelines, and multimodal knowledge retrieval.",
    examFocus: "Deep knowledge of RAG pipeline components (chunking, embedding, retrieval, reranking, generation), vector database concepts (similarity search, metadata filtering), hybrid search, and ETL for knowledge bases. Know RAGAS metrics and GraphRAG.",
    concepts: [
      { name: "RAG (Retrieval-Augmented Generation)", def: "Pattern that retrieves relevant documents from a knowledge base and includes them in the LLM context before generation, grounding responses in factual, current information." },
      { name: "Vector Embeddings", def: "Dense numerical representations of text (or other data) that capture semantic meaning, enabling similarity-based search across a knowledge base." },
      { name: "Cosine Similarity", def: "Metric measuring the angle between two vectors, used to find semantically similar documents. Values range from -1 to 1, with 1 being identical." },
      { name: "Hybrid Search", def: "Combines dense vector search (semantic) with sparse keyword search (BM25), leveraging the strengths of both for superior retrieval quality." },
      { name: "Reranker (Cross-Encoder)", def: "Model that scores query-document pairs together for more accurate relevance scoring, reordering initial retrieval results to improve context quality." },
      { name: "Chunking", def: "Splitting documents into smaller segments for indexing. Chunk size balances retrieval precision (smaller) with context completeness (larger)." },
      { name: "ETL Pipeline", def: "Extract, Transform, Load ‚Äî ingesting data from sources, processing/cleaning it, and loading it into the vector database for retrieval." },
      { name: "Metadata Filtering", def: "Pre-filtering documents by structured attributes (date, category, author) before or after vector search to narrow results and improve precision." },
      { name: "GraphRAG", def: "RAG approach using knowledge graphs to capture entity relationships, enabling multi-hop reasoning across connected facts." },
      { name: "HNSW Index", def: "Hierarchical Navigable Small World ‚Äî approximate nearest neighbor algorithm used in vector databases for fast, scalable similarity search." },
      { name: "Embedding Model", def: "Model that converts text (or other data) into vector embeddings. Examples: text-embedding-3-large (OpenAI), NV-Embed (NVIDIA), E5, BGE." },
      { name: "Sparse Retrieval (BM25)", def: "Keyword-based retrieval using term frequency and inverse document frequency. Effective for exact term matches and technical terminology." }
    ],
    subtopics: [
      { num: "6.1", title: "Design and implement RAG pipelines for knowledge-grounded responses", desc: "RAG pipelines: ingest documents ‚Üí chunk ‚Üí embed ‚Üí store in vector DB ‚Üí retrieve relevant chunks ‚Üí rerank ‚Üí augment prompt ‚Üí generate grounded response." },
      { num: "6.2", title: "Select and configure vector databases for semantic search", desc: "Vector databases (Milvus, Pinecone, Weaviate, Qdrant) store embeddings and support similarity search. Selection criteria: scalability, filtering capabilities, GPU acceleration, and cloud/on-premises deployment." },
      { num: "6.3", title: "Implement hybrid search combining dense and sparse retrieval", desc: "Hybrid search combines vector search (semantic understanding) with BM25 (keyword matching). Results are fused using Reciprocal Rank Fusion (RRF) or weighted combination." },
      { num: "6.4", title: "Build ETL pipelines for knowledge base construction and maintenance", desc: "ETL pipelines ingest data from diverse sources (PDFs, databases, APIs, web), transform it (clean, chunk, embed), and load it into the vector database with scheduled updates." },
      { num: "6.5", title: "Apply reranking to improve retrieval quality", desc: "Cross-encoder rerankers score query-document pairs together for more accurate relevance than bi-encoder retrieval. Applied after initial retrieval to reorder top-k results." },
      { num: "6.6", title: "Integrate knowledge graphs for relational reasoning (GraphRAG)", desc: "GraphRAG combines vector search with knowledge graph traversal, enabling multi-hop reasoning across entity relationships for complex queries." }
    ],
    frameworks: [
      { name: "LlamaIndex", purpose: "Data framework for LLM applications", feature: "Document loading, chunking, indexing, querying" },
      { name: "LangChain", purpose: "LLM application framework with RAG support", feature: "Document loaders, vector stores, retrievers" },
      { name: "Milvus + NVIDIA RAFT", purpose: "GPU-accelerated vector database", feature: "GPU-accelerated ANN search, billion-scale" },
      { name: "Pinecone", purpose: "Managed vector database", feature: "Serverless, metadata filtering, hybrid search" },
      { name: "Weaviate", purpose: "Open-source vector database", feature: "Hybrid search, GraphQL API, multi-tenancy" },
      { name: "NVIDIA NeMo Retriever", purpose: "Enterprise retrieval microservices", feature: "Embedding NIM, reranking NIM" },
      { name: "Neo4j", purpose: "Graph database for GraphRAG", feature: "Cypher query language, graph algorithms" },
      { name: "Unstructured.io", purpose: "Document parsing and ETL", feature: "PDF, Word, HTML extraction, chunking" }
    ],
    resources: [
      { icon: "üéì", type: "nvidia", title: "Building RAG Agents with LLMs", sub: "NVIDIA DLI Course ¬∑ 8 hrs ¬∑ Primary" },
      { icon: "üéì", type: "nvidia", title: "Evaluating RAG and Semantic Search Systems", sub: "NVIDIA DLI Course ¬∑ 3 hrs" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA NeMo Retriever Documentation", sub: "NVIDIA Developer Docs" },
      { icon: "üìÑ", type: "external", title: "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", sub: "Meta AI Research Paper" },
      { icon: "üìÑ", type: "external", title: "From Local to Global: A Graph RAG Approach", sub: "Microsoft Research Paper" },
      { icon: "üìÑ", type: "external", title: "LlamaIndex Documentation", sub: "docs.llamaindex.ai" }
    ]
  },

  7: {
    title: "NVIDIA Platform Implementation",
    weight: "7%",
    tag: "NVIDIA Stack",
    desc: "Leveraging NVIDIA's comprehensive AI hardware and software platform ‚Äî NIM microservices, NeMo Framework, TensorRT-LLM, Triton Inference Server, AIQ Toolkit, NeMo Guardrails, and NVIDIA AI Blueprints.",
    examFocus: "Know each NVIDIA product's specific purpose: NIM (inference microservices), NeMo (training/fine-tuning), TensorRT-LLM (inference optimization), Triton (serving), AIQ (evaluation), Guardrails (safety), Blueprints (reference architectures). Understand in-flight batching and paged KV cache.",
    concepts: [
      { name: "NVIDIA NIM", def: "NVIDIA Inference Microservices ‚Äî containerized, GPU-optimized inference services with OpenAI-compatible APIs, deployable anywhere NVIDIA GPUs are available." },
      { name: "NVIDIA NeMo Framework", def: "Scalable framework for training, fine-tuning, and customizing generative AI models including LLMs, with support for distributed training and PEFT techniques." },
      { name: "TensorRT-LLM", def: "Open-source library for optimizing LLM inference on NVIDIA GPUs using quantization, kernel fusion, in-flight batching, and paged KV cache." },
      { name: "NVIDIA Triton Inference Server", def: "Open-source inference serving platform supporting multiple ML frameworks with dynamic batching, concurrent model execution, and model ensembles." },
      { name: "NVIDIA AIQ Toolkit", def: "Agent Intelligence Toolkit for building, evaluating, and profiling agentic AI workflows with NVIDIA's ecosystem." },
      { name: "NeMo Guardrails", def: "Open-source toolkit for adding programmable safety rails to LLM applications using the Colang domain-specific language." },
      { name: "NVIDIA AI Blueprints", def: "Reference architectures and pre-built workflows for common agentic AI use cases (PDF RAG, video search, customer service) that can be customized and deployed." },
      { name: "In-Flight Batching", def: "Continuous batching that processes requests as they arrive without waiting for complete batches, maximizing GPU utilization and throughput." },
      { name: "Paged KV Cache", def: "Dynamically allocates fixed-size 'pages' of KV cache memory (analogous to OS virtual memory paging), dramatically improving memory efficiency." },
      { name: "Quantization (FP8/INT8)", def: "Reducing model weight precision from FP32/FP16 to lower precision formats, reducing memory footprint and increasing throughput with minimal accuracy loss." },
      { name: "Colang", def: "Domain-specific language used by NeMo Guardrails to define conversational flows, safety constraints, and compliance rules." },
      { name: "NVIDIA cuVS", def: "CUDA Vector Search ‚Äî GPU-accelerated library for building and querying vector indexes, used in GPU-accelerated RAG pipelines." }
    ],
    subtopics: [
      { num: "7.1", title: "Deploy AI models using NVIDIA NIM for optimized inference", desc: "NIM provides pre-built, optimized containers for LLMs, embedding models, and multimodal models. Deploy with docker run or Kubernetes, expose OpenAI-compatible API, and integrate with existing LangChain/LlamaIndex applications." },
      { num: "7.2", title: "Fine-tune and customize models with NVIDIA NeMo Framework", desc: "NeMo supports SFT, LoRA, P-tuning, and RLHF for model customization. Distributed training across multiple GPUs enables fine-tuning of large models efficiently." },
      { num: "7.3", title: "Optimize inference performance with TensorRT-LLM", desc: "TensorRT-LLM applies quantization (FP8, INT8, INT4), kernel fusion, in-flight batching, and paged KV cache to maximize throughput and minimize latency on NVIDIA GPUs." },
      { num: "7.4", title: "Implement safety controls using NeMo Guardrails", desc: "NeMo Guardrails uses Colang to define topical constraints, safety boundaries, and fact-checking rules. Integrates with any LLM via LangChain or direct API." },
      { num: "7.5", title: "Leverage NVIDIA AI Blueprints for accelerated development", desc: "Blueprints provide production-ready reference architectures for common use cases. Customize the blueprint components (models, retrieval, UI) for specific enterprise requirements." },
      { num: "7.6", title: "Evaluate and profile agent workflows with the AIQ Toolkit", desc: "AIQ Toolkit profiles agent execution, identifies bottlenecks, and compares configurations. Integrates with NIM for end-to-end NVIDIA stack evaluation." }
    ],
    frameworks: [
      { name: "NVIDIA NIM", purpose: "Containerized inference microservices", feature: "OpenAI-compatible API, GPU-optimized, any cloud" },
      { name: "NVIDIA NeMo", purpose: "LLM training and fine-tuning", feature: "Distributed training, LoRA, SFT, RLHF" },
      { name: "TensorRT-LLM", purpose: "LLM inference optimization", feature: "Quantization, kernel fusion, in-flight batching" },
      { name: "Triton Inference Server", purpose: "Multi-framework model serving", feature: "Dynamic batching, concurrent execution" },
      { name: "NeMo Guardrails", purpose: "LLM safety and compliance", feature: "Colang DSL, topical/safety/fact-check rails" },
      { name: "NVIDIA AIQ Toolkit", purpose: "Agentic workflow evaluation", feature: "Profiling, benchmarking, optimization" },
      { name: "NVIDIA AI Blueprints", purpose: "Reference architectures", feature: "PDF RAG, video search, customer service" },
      { name: "cuVS / RAFT", purpose: "GPU-accelerated vector search", feature: "GPU ANN indexes, billion-scale search" }
    ],
    resources: [
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA NIM Documentation", sub: "docs.api.nvidia.com ¬∑ Official Reference" },
      { icon: "üìÑ", type: "nvidia", title: "TensorRT-LLM Documentation", sub: "NVIDIA Developer Docs" },
      { icon: "üìÑ", type: "nvidia", title: "NeMo Guardrails Documentation", sub: "docs.nvidia.com/nemo/guardrails" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA AI Blueprints", sub: "build.nvidia.com/blueprints" },
      { icon: "üéì", type: "nvidia", title: "Building RAG Agents with LLMs", sub: "NVIDIA DLI Course ¬∑ Uses NIM throughout" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA AIQ Toolkit GitHub", sub: "github.com/NVIDIA/AIQToolkit" }
    ]
  },

  8: {
    title: "Run, Monitor & Maintain",
    weight: "5%",
    tag: "Operations",
    desc: "Ongoing operation, monitoring, and maintenance of agentic AI systems post-deployment ‚Äî observability, drift detection, feedback loops, alerting, knowledge base maintenance, and model versioning.",
    examFocus: "Know the three pillars of observability (logs, metrics, traces), key production metrics (P99 latency, error rate, throughput), drift detection strategies, feedback loop design, and knowledge base maintenance approaches.",
    concepts: [
      { name: "Observability", def: "The ability to understand a system's internal state from its external outputs. Three pillars: logs (events), metrics (measurements), traces (request flows)." },
      { name: "Distributed Tracing", def: "Tracking requests as they flow through multiple services, visualizing the complete execution path to identify latency bottlenecks and failures." },
      { name: "P99 Latency", def: "99th percentile response time ‚Äî 99% of requests complete faster than this value. Captures tail latency experienced by the worst 1% of users." },
      { name: "Error Rate", def: "Percentage of requests that fail or return errors. Critical SLO metric ‚Äî sudden spikes indicate system problems requiring immediate investigation." },
      { name: "Data Drift", def: "Gradual shift in input data distribution away from training distribution, causing model performance degradation over time." },
      { name: "Concept Drift", def: "Change in the relationship between inputs and outputs over time (e.g., word meanings change), causing model predictions to become less accurate." },
      { name: "Feedback Loop", def: "Mechanism for collecting user feedback and system performance data to continuously improve the agent through prompt updates, retraining, or knowledge base refresh." },
      { name: "Anomaly Detection", def: "Continuously monitoring metrics and automatically alerting when values deviate significantly from historical baselines, enabling proactive issue identification." },
      { name: "SLO (Service Level Objective)", def: "Target value for a service metric (e.g., P99 latency < 2s, error rate < 0.1%). SLOs define acceptable service quality levels." },
      { name: "Knowledge Base Staleness", def: "Degradation of retrieval quality as indexed documents become outdated relative to current information, requiring periodic refresh." },
      { name: "Canary Analysis", def: "Automatically comparing metrics between a canary deployment and baseline to detect regressions, triggering automatic rollback if degradation is detected." },
      { name: "Model Versioning", def: "Tracking which version of each model component is deployed, enabling rollback, A/B testing, audit trails, and reproducibility." }
    ],
    subtopics: [
      { num: "8.1", title: "Implement comprehensive observability (logs, metrics, traces)", desc: "Structured logging captures discrete events; metrics track numerical measurements over time; distributed traces visualize end-to-end request flows. Together they provide full system visibility." },
      { num: "8.2", title: "Monitor for data drift and model performance degradation", desc: "Statistical tests (KS test, PSI) detect distribution shifts in inputs. Performance metrics (accuracy, user satisfaction) detect output quality degradation. Both require automated alerting." },
      { num: "8.3", title: "Design feedback loops for continuous improvement", desc: "Feedback loops collect signals (user ratings, thumbs up/down, explicit corrections) and route them to improvement workflows (prompt updates, fine-tuning, knowledge base refresh)." },
      { num: "8.4", title: "Maintain knowledge bases with regular updates and quality checks", desc: "Scheduled ETL pipelines re-ingest updated sources. Change detection identifies modified documents. Quality checks verify embedding quality and retrieval accuracy over time." },
      { num: "8.5", title: "Implement alerting and incident response procedures", desc: "Automated alerts on SLO breaches trigger incident response. Runbooks document standard remediation procedures. Post-mortems capture learnings to prevent recurrence." }
    ],
    frameworks: [
      { name: "Prometheus", purpose: "Metrics collection and storage", feature: "Time-series DB, PromQL, alerting rules" },
      { name: "Grafana", purpose: "Metrics visualization and dashboards", feature: "Custom dashboards, alert management" },
      { name: "Jaeger / Zipkin", purpose: "Distributed tracing", feature: "Request flow visualization, latency analysis" },
      { name: "ELK Stack", purpose: "Log aggregation and search", feature: "Elasticsearch, Logstash, Kibana" },
      { name: "Arize AI / Whylogs", purpose: "ML monitoring and drift detection", feature: "Data drift, model performance monitoring" },
      { name: "LangSmith", purpose: "LLM application tracing", feature: "Trace visualization, evaluation datasets" },
      { name: "PagerDuty / OpsGenie", purpose: "Incident management and alerting", feature: "On-call routing, escalation policies" },
      { name: "MLflow", purpose: "ML lifecycle management", feature: "Experiment tracking, model registry" }
    ],
    resources: [
      { icon: "üéì", type: "nvidia", title: "Introduction to Deploying RAG Pipelines for Production at Scale", sub: "NVIDIA DLI Course" },
      { icon: "üìÑ", type: "external", title: "Google SRE Book ‚Äî Monitoring Distributed Systems", sub: "sre.google/sre-book" },
      { icon: "üìÑ", type: "external", title: "Prometheus Documentation", sub: "prometheus.io/docs" },
      { icon: "üìÑ", type: "external", title: "OpenTelemetry Documentation", sub: "opentelemetry.io ¬∑ Observability standard" },
      { icon: "üìÑ", type: "external", title: "ML Monitoring Best Practices", sub: "Evidently AI Blog" },
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA AIQ Toolkit ‚Äî Monitoring Integration", sub: "NVIDIA Developer Docs" }
    ]
  },

  9: {
    title: "Safety, Ethics & Compliance",
    weight: "5%",
    tag: "Responsible AI",
    desc: "Responsible AI development and deployment ‚Äî guardrails, prompt injection defense, bias mitigation, privacy compliance (GDPR), content moderation, audit trails, and regulatory frameworks (EU AI Act).",
    examFocus: "Know the EU AI Act risk categories, GDPR key rights (erasure, access, portability), NeMo Guardrails and Colang, prompt injection attacks and defenses, algorithmic bias mitigation, and the principles of responsible AI (fairness, accountability, transparency).",
    concepts: [
      { name: "Prompt Injection", def: "Attack where malicious instructions in user input or retrieved content override the agent's system prompt, causing unintended behavior or data exfiltration." },
      { name: "NeMo Guardrails", def: "NVIDIA's open-source toolkit for adding programmable safety rails using Colang DSL ‚Äî topical, safety, and fact-checking constraints." },
      { name: "Colang", def: "Domain-specific language for NeMo Guardrails that defines conversational flows, safety constraints, and compliance rules in a readable format." },
      { name: "EU AI Act", def: "World's first comprehensive AI regulation categorizing systems by risk: unacceptable (banned), high (strict requirements), limited (transparency), minimal (no requirements)." },
      { name: "GDPR", def: "General Data Protection Regulation ‚Äî EU privacy law governing personal data processing. Key rights: access, erasure, portability, rectification, restriction." },
      { name: "Right to Erasure", def: "GDPR Article 17 ‚Äî individuals can request deletion of their personal data from AI systems, including vector databases, conversation logs, and training datasets." },
      { name: "Algorithmic Bias", def: "Systematic unfair discrimination in AI outputs due to biased training data or model design. Mitigated through diverse data, bias audits, and fairness constraints." },
      { name: "Audit Trail", def: "Comprehensive, tamper-evident record of all agent decisions, actions, and data accesses for accountability and regulatory compliance." },
      { name: "Data Minimization", def: "GDPR principle requiring collection of only the minimum personal data necessary for the specified purpose." },
      { name: "Content Moderation", def: "Detecting and filtering harmful content (toxicity, hate speech, PII) in agent inputs and outputs using classifiers, rules, or LLM-based moderation." },
      { name: "Explainability (XAI)", def: "Ability to provide human-understandable explanations for AI decisions, required by GDPR Article 22 and EU AI Act for automated decision-making." },
      { name: "Differential Privacy", def: "Mathematical framework for adding calibrated noise to data or model outputs to protect individual privacy while preserving statistical utility." }
    ],
    subtopics: [
      { num: "9.1", title: "Implement guardrails to prevent harmful outputs and prompt injection", desc: "NeMo Guardrails uses Colang to define safety boundaries. Input validation, output filtering, and prompt hardening defend against injection attacks. Sandboxing limits agent capabilities." },
      { num: "9.2", title: "Apply bias detection and mitigation techniques", desc: "Bias audits measure disparate impact across demographic groups. Mitigation: diverse training data, fairness constraints, re-weighting, and adversarial debiasing. Regular production monitoring detects emerging bias." },
      { num: "9.3", title: "Ensure compliance with GDPR and data privacy regulations", desc: "GDPR compliance requires: data minimization, purpose limitation, consent management, data subject rights (access, erasure, portability), privacy by design, and data breach notification." },
      { num: "9.4", title: "Understand and apply EU AI Act requirements", desc: "High-risk AI systems require: conformity assessment, technical documentation, human oversight measures, accuracy and robustness requirements, and registration in the EU database." },
      { num: "9.5", title: "Maintain audit trails for accountability and compliance", desc: "Comprehensive logging of agent decisions, tool invocations, and data accesses. Tamper-evident storage, retention policies, and access controls ensure audit trail integrity." },
      { num: "9.6", title: "Implement content moderation for safe agent interactions", desc: "Multi-layer content moderation: input filtering (block harmful queries), output filtering (detect harmful responses), and PII detection/redaction. NeMo Guardrails provides a framework for this." }
    ],
    frameworks: [
      { name: "NeMo Guardrails", purpose: "LLM safety and compliance framework", feature: "Colang DSL, topical/safety/fact-check rails" },
      { name: "Llama Guard", purpose: "Content safety classification", feature: "Input/output safety classification" },
      { name: "Presidio", purpose: "PII detection and anonymization", feature: "Named entity recognition, redaction" },
      { name: "Fairlearn", purpose: "Algorithmic fairness assessment", feature: "Fairness metrics, mitigation algorithms" },
      { name: "AI Fairness 360", purpose: "Bias detection toolkit", feature: "70+ fairness metrics, bias mitigation" },
      { name: "SHAP / LIME", purpose: "Model explainability", feature: "Feature importance, local explanations" },
      { name: "OpenDP", purpose: "Differential privacy library", feature: "Privacy-preserving data analysis" },
      { name: "OneTrust", purpose: "Privacy compliance management", feature: "GDPR consent, data mapping, DSR management" }
    ],
    resources: [
      { icon: "üìÑ", type: "nvidia", title: "NeMo Guardrails Documentation", sub: "docs.nvidia.com/nemo/guardrails" },
      { icon: "üìÑ", type: "external", title: "EU AI Act Full Text", sub: "eur-lex.europa.eu" },
      { icon: "üìÑ", type: "external", title: "GDPR Key Principles", sub: "gdpr.eu ¬∑ Official Resource" },
      { icon: "üìÑ", type: "external", title: "NIST AI Risk Management Framework", sub: "nist.gov/system/files/documents/2023/01/26/AI RMF 1.0.pdf" },
      { icon: "üìÑ", type: "external", title: "Prompt Injection Attacks and Defenses", sub: "OWASP LLM Top 10" },
      { icon: "üìÑ", type: "external", title: "Responsible AI Practices", sub: "Google AI Principles" }
    ]
  },

  10: {
    title: "Human-AI Interaction & Oversight",
    weight: "5%",
    tag: "Human Oversight",
    desc: "Design of systems facilitating effective human oversight of AI agents ‚Äî human-in-the-loop patterns, transparency, explainability, tiered autonomy, automation bias prevention, and contestability.",
    examFocus: "Understand HITL design patterns, automation bias and how to mitigate it, tiered autonomy frameworks, meaningful human control requirements, progressive disclosure in UI design, and contestability as an ethical/legal requirement.",
    concepts: [
      { name: "Human-in-the-Loop (HITL)", def: "Design pattern integrating human judgment into agent workflows at critical decision points, particularly for high-stakes or uncertain situations." },
      { name: "Automation Bias", def: "Human tendency to over-rely on automated systems, accepting AI recommendations without sufficient critical evaluation ‚Äî a major risk in HITL systems." },
      { name: "Tiered Autonomy", def: "Framework assigning different autonomy levels based on task risk and confidence: low-risk actions automated, high-risk actions require human approval." },
      { name: "Meaningful Human Control", def: "Requires humans to have: (1) sufficient understanding of AI actions, (2) capability to effectively intervene, and (3) authority to override decisions." },
      { name: "Contestability", def: "The right and ability for affected individuals to challenge, appeal, or seek redress for AI decisions ‚Äî a fundamental ethical and legal requirement." },
      { name: "Progressive Disclosure", def: "Presenting summary information by default with deeper details available on demand, preventing information overload while maintaining transparency." },
      { name: "Transparency", def: "Making AI system behavior, reasoning, and limitations understandable to users and overseers ‚Äî foundational for trust and meaningful oversight." },
      { name: "Human-Centered AI Design", def: "Designing AI systems that augment human capabilities, respect human values, maintain human agency, and are accessible and understandable." },
      { name: "Skill Preservation", def: "Intentionally keeping humans engaged in decision-making to prevent over-reliance on AI and maintain human capability for situations where AI is unavailable or incorrect." },
      { name: "Confidence Calibration", def: "Ensuring the agent accurately communicates its uncertainty ‚Äî neither overconfident nor underconfident ‚Äî enabling users to appropriately calibrate their trust." },
      { name: "Intervention Points", def: "Designated moments in agent workflows where humans can review, modify, approve, or reject agent decisions before execution continues." },
      { name: "Explainability (XAI)", def: "Providing human-understandable explanations for AI decisions ‚Äî what factors drove the decision, what alternatives were considered, and how confident the system is." }
    ],
    subtopics: [
      { num: "10.1", title: "Design human-in-the-loop systems for appropriate oversight", desc: "HITL design identifies which decisions require human oversight (based on risk, reversibility, confidence), designs intervention points, and ensures humans have the context needed to make informed decisions." },
      { num: "10.2", title: "Mitigate automation bias through interface and process design", desc: "Mitigation strategies: requiring active confirmation (not just passive approval), showing alternative options, displaying confidence scores, providing reasoning explanations, and training users on AI limitations." },
      { num: "10.3", title: "Implement tiered autonomy based on risk and confidence", desc: "Define autonomy tiers: fully automated (low risk, high confidence), notify-only (medium risk), approval required (high risk), human-led (critical/irreversible). Dynamically adjust based on context." },
      { num: "10.4", title: "Ensure transparency and explainability in agent decision-making", desc: "Provide: reasoning chain visibility, tool call logs, confidence scores, alternative options considered, and plain-language explanations of decisions. Progressive disclosure manages information complexity." },
      { num: "10.5", title: "Design for contestability and user agency", desc: "Implement: clear appeal mechanisms, ability to provide additional context, human review escalation paths, and feedback channels. Document decision rationale for audit and appeal purposes." }
    ],
    frameworks: [
      { name: "LangGraph HITL", purpose: "Human-in-the-loop workflow interrupts", feature: "Interrupt nodes, human approval gates" },
      { name: "NVIDIA AIQ Toolkit", purpose: "Agent workflow transparency", feature: "Decision trace visualization, profiling" },
      { name: "Gradio / Streamlit", purpose: "Human oversight interfaces", feature: "Approval UIs, trace visualization" },
      { name: "SHAP / LIME", purpose: "Decision explainability", feature: "Feature importance, local explanations" },
      { name: "Human Protocol", purpose: "Human task management for AI oversight", feature: "Task routing, human review queues" },
      { name: "Argilla", purpose: "Human feedback collection platform", feature: "Annotation, feedback loops, RLHF data" },
      { name: "Scale AI", purpose: "Human data labeling and evaluation", feature: "Expert human evaluation, RLHF" },
      { name: "EU AI Act Compliance Tools", purpose: "Regulatory compliance for high-risk AI", feature: "Conformity assessment, documentation" }
    ],
    resources: [
      { icon: "üìÑ", type: "nvidia", title: "NVIDIA Responsible AI Principles", sub: "nvidia.com/en-us/ai-data-science/responsible-ai" },
      { icon: "üìÑ", type: "external", title: "Human-Centered AI Design Guidelines", sub: "Google PAIR Guidebook" },
      { icon: "üìÑ", type: "external", title: "Meaningful Human Control of AI Systems", sub: "ICRC Research Paper" },
      { icon: "üìÑ", type: "external", title: "Automation Bias in AI-Assisted Decision Making", sub: "ACM Digital Library" },
      { icon: "üìÑ", type: "external", title: "EU AI Act ‚Äî Human Oversight Requirements", sub: "European Commission" },
      { icon: "üìÑ", type: "external", title: "Tiered Autonomy in Human-Robot Interaction", sub: "IEEE Robotics Survey" }
    ]
  }
};

</script>
<script>
// NCP-AAI Study Guide ‚Äî Main Application Logic

// ‚îÄ‚îÄ State ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
let currentPage = 'home';
let openChapters = new Set();
let quizState = {}; // { chapterId: { answers: {}, revealed: Set } }

// ‚îÄ‚îÄ Navigation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function showPage(pageId) {
  // Hide all pages
  document.querySelectorAll('.page').forEach(p => p.classList.remove('active'));
  // Show target page
  const target = document.getElementById('page-' + pageId);
  if (target) {
    target.classList.add('active');
    currentPage = pageId;
    // Scroll to top
    window.scrollTo({ top: 0, behavior: 'smooth' });
    // Update sidebar active state
    updateSidebarActive(pageId);
    // Update progress bar
    updateProgressBar();
    // Render chapter content if needed
    if (pageId.startsWith('ch') && pageId !== 'ch1' && pageId !== 'ch2') {
      const chNum = parseInt(pageId.replace('ch', ''));
      if (chNum >= 3 && chNum <= 10) {
        renderChapter(chNum);
      }
    }
    // Render full exam if needed
    if (pageId === 'full-test') {
      renderQuiz('full');
    }
  }
}

function toggleChapter(num) {
  const sub = document.getElementById('nav-sub-' + num);
  if (!sub) return;
  if (openChapters.has(num)) {
    sub.classList.remove('open');
    openChapters.delete(num);
  } else {
    sub.classList.add('open');
    openChapters.add(num);
  }
}

function toggleSidebar() {
  const sidebar = document.getElementById('sidebar');
  sidebar.classList.toggle('open');
}

function updateSidebarActive(pageId) {
  document.querySelectorAll('.nav-chapter-btn').forEach(btn => btn.classList.remove('active'));
  document.querySelectorAll('.nav-special-btn').forEach(btn => btn.classList.remove('active'));
  if (pageId === 'home') {
    const homeBtn = document.querySelector('[onclick="showPage(\'home\')"]');
    if (homeBtn) homeBtn.classList.add('active');
  } else if (pageId.startsWith('ch')) {
    const chNum = parseInt(pageId.replace('ch', ''));
    const navSection = document.getElementById('nav-ch' + chNum);
    if (navSection) {
      const btn = navSection.querySelector('.nav-chapter-btn');
      if (btn) btn.classList.add('active');
    }
  } else if (pageId === 'full-test') {
    const testBtn = document.querySelector('.nav-special-btn');
    if (testBtn) testBtn.classList.add('active');
  }
}

function updateProgressBar() {
  const pages = ['home', 'ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8', 'ch9', 'ch10', 'full-test'];
  const idx = pages.indexOf(currentPage);
  const pct = idx >= 0 ? (idx / (pages.length - 1)) * 100 : 0;
  const bar = document.getElementById('progress-bar');
  if (bar) bar.style.width = pct + '%';
}

function scrollToSection(sectionId) {
  setTimeout(() => {
    const el = document.getElementById(sectionId);
    if (el) {
      const topOffset = 130; // topbar + sticky nav height
      const top = el.getBoundingClientRect().top + window.pageYOffset - topOffset;
      window.scrollTo({ top, behavior: 'smooth' });
    }
  }, 100);
}

function filterNav(query) {
  const q = query.toLowerCase();
  document.querySelectorAll('.nav-chapter-btn').forEach(btn => {
    const searchData = btn.getAttribute('data-search') || '';
    const text = btn.textContent.toLowerCase();
    const match = !q || searchData.includes(q) || text.includes(q);
    btn.closest('.nav-section').style.display = match ? '' : 'none';
  });
}

// ‚îÄ‚îÄ Chapter Rendering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function renderChapter(chNum) {
  const container = document.getElementById('ch' + chNum + '-content');
  if (!container || container.dataset.rendered) return;
  
  const data = CHAPTER_DATA[chNum];
  if (!data) return;

  const prevCh = chNum > 1 ? chNum - 1 : null;
  const nextCh = chNum < 10 ? chNum + 1 : null;

  container.innerHTML = `
    <div class="sticky-chapter-nav">
      <span class="sticky-nav-item active" onclick="scrollToSection('concepts-${chNum}')">Key Concepts</span>
      <span class="sticky-nav-item" onclick="scrollToSection('subtopics-${chNum}')">Subtopics</span>
      <span class="sticky-nav-item" onclick="scrollToSection('frameworks-${chNum}')">Frameworks</span>
      <span class="sticky-nav-item" onclick="scrollToSection('resources-${chNum}')">Resources</span>
      <span class="sticky-nav-item" onclick="scrollToSection('practice-${chNum}')">Practice Test</span>
    </div>
    <div class="chapter-page">
      <div class="chapter-header">
        <div class="ch-meta">
          <span class="tag tag-green">Chapter ${chNum}</span>
          <span class="tag tag-green">${data.weight} of Exam</span>
          <span class="tag tag-blue">${data.tag}</span>
        </div>
        <h1>${data.title}</h1>
        <p class="ch-desc">${data.desc}</p>
      </div>

      <div class="callout callout-tip">
        <span class="callout-icon">üí°</span>
        <div class="callout-content"><strong>Exam Focus:</strong> ${data.examFocus}</div>
      </div>

      <!-- Key Concepts -->
      <div class="content-section" id="concepts-${chNum}">
        <h2><span class="section-icon">üß†</span> Key Concepts</h2>
        <div class="concept-grid">
          ${data.concepts.map(c => `
            <div class="concept-card">
              <div class="concept-name">${c.name}</div>
              <div class="concept-def">${c.def}</div>
            </div>
          `).join('')}
        </div>
      </div>

      <!-- Subtopics -->
      <div class="content-section" id="subtopics-${chNum}">
        <h2><span class="section-icon">üìã</span> Official Exam Subtopics</h2>
        <ul class="subtopics-list">
          ${data.subtopics.map(s => `
            <li>
              <span class="subtopic-num">${s.num}</span>
              <div class="subtopic-content">
                <div class="subtopic-title">${s.title}</div>
                <div class="subtopic-desc">${s.desc}</div>
              </div>
            </li>
          `).join('')}
        </ul>
      </div>

      <!-- Frameworks -->
      <div class="content-section" id="frameworks-${chNum}">
        <h2><span class="section-icon">üîß</span> Frameworks, Tools &amp; Patterns</h2>
        <table class="frameworks-table">
          <thead>
            <tr><th>Framework / Tool</th><th>Purpose</th><th>Key Feature</th></tr>
          </thead>
          <tbody>
            ${data.frameworks.map(f => `
              <tr>
                <td><strong>${f.name}</strong></td>
                <td>${f.purpose}</td>
                <td>${f.feature}</td>
              </tr>
            `).join('')}
          </tbody>
        </table>
      </div>

      <!-- Resources -->
      <div class="content-section" id="resources-${chNum}">
        <h2><span class="section-icon">üìö</span> Recommended Resources</h2>
        <div class="resources-grid">
          ${data.resources.map(r => `
            <div class="resource-card">
              <div class="resource-icon ${r.type}">${r.icon}</div>
              <div class="resource-info">
                <div class="resource-title">${r.title}</div>
                <div class="resource-type">${r.sub}</div>
              </div>
            </div>
          `).join('')}
        </div>
      </div>

      <!-- Practice Test -->
      <div class="practice-section" id="practice-${chNum}">
        <div class="practice-header">
          <h2>üìù Practice Test ‚Äî Chapter ${chNum}</h2>
          <div class="practice-stats">
            <span class="practice-stat">Questions: <span id="q-count-${chNum}">10</span></span>
            <span class="practice-stat">Score: <span id="score-${chNum}">0/0</span></span>
          </div>
        </div>
        <div class="quiz-controls">
          <button class="btn btn-primary btn-sm" onclick="checkAll(${chNum})">Check All Answers</button>
          <button class="btn btn-reset btn-sm" onclick="resetQuiz(${chNum})">Reset Quiz</button>
          <button class="btn btn-outline btn-sm" onclick="revealAll(${chNum})">Reveal All Answers</button>
        </div>
        <div id="quiz-${chNum}"></div>
        <div class="score-board" id="score-board-${chNum}">
          <div class="score-circle"><span class="score-num" id="score-pct-${chNum}">0%</span></div>
          <div class="score-label" id="score-msg-${chNum}">Complete the quiz to see your score</div>
          <div class="score-sub" id="score-detail-${chNum}"></div>
        </div>
      </div>

      <div class="page-footer">
        <div class="footer-info">Chapter ${chNum} of 10 ¬∑ ${data.title} ¬∑ ${data.weight} of Exam</div>
        <div class="footer-nav">
          ${prevCh ? `<button class="btn btn-outline btn-sm" onclick="showPage('ch${prevCh}')">‚Üê Chapter ${prevCh}</button>` : `<button class="btn btn-outline btn-sm" onclick="showPage('home')">‚Üê Overview</button>`}
          ${nextCh ? `<button class="btn btn-primary btn-sm" onclick="showPage('ch${nextCh}')">Chapter ${nextCh} ‚Üí</button>` : `<button class="btn btn-primary btn-sm" onclick="showPage('full-test')">Practice Exam ‚Üí</button>`}
        </div>
      </div>
    </div>
  `;

  container.dataset.rendered = 'true';
  
  // Render the quiz for this chapter
  renderQuiz(chNum);
}

// ‚îÄ‚îÄ Quiz Rendering ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function renderQuiz(chapterId) {
  const container = document.getElementById('quiz-' + chapterId);
  if (!container) return;
  
  const questions = QUIZ_DATA[chapterId];
  if (!questions) return;

  // Initialize state
  if (!quizState[chapterId]) {
    quizState[chapterId] = { answers: {}, revealed: new Set() };
  }

  container.innerHTML = questions.map((q, idx) => {
    const letters = ['A', 'B', 'C', 'D'];
    const state = quizState[chapterId];
    const selected = state.answers[idx];
    const revealed = state.revealed.has(idx);
    
    return `
      <div class="question-card" id="qcard-${chapterId}-${idx}">
        <div class="question-num">Question ${idx + 1} of ${questions.length}${q.chapter ? ' ¬∑ Chapter ' + q.chapter : ''}</div>
        <div class="question-text">${q.q}</div>
        <ul class="options-list">
          ${q.opts.map((opt, oi) => {
            let cls = '';
            if (revealed) {
              cls = oi === q.ans ? 'correct' : (oi === selected ? 'wrong' : '');
            } else if (oi === selected) {
              cls = 'selected';
            }
            return `
              <li class="option-item ${cls}" onclick="selectOption('${chapterId}', ${idx}, ${oi})" id="opt-${chapterId}-${idx}-${oi}">
                <span class="option-letter">${letters[oi]}</span>
                <span class="option-text">${opt}</span>
              </li>
            `;
          }).join('')}
        </ul>
        <div class="explanation-box ${revealed ? 'show' : ''}" id="exp-${chapterId}-${idx}">
          <strong>‚úÖ Correct Answer: ${letters[q.ans]}</strong><br/>${q.exp}
        </div>
        <div class="question-actions">
          <button class="btn btn-check btn-sm" onclick="checkAnswer('${chapterId}', ${idx})">Check Answer</button>
          <button class="btn btn-reveal btn-sm" onclick="revealAnswer('${chapterId}', ${idx})">Reveal Answer</button>
        </div>
      </div>
    `;
  }).join('');
}

function selectOption(chapterId, qIdx, optIdx) {
  const state = quizState[chapterId];
  if (!state) return;
  if (state.revealed.has(qIdx)) return; // Don't allow selection after reveal
  
  state.answers[qIdx] = optIdx;
  
  // Update UI
  const questions = QUIZ_DATA[chapterId];
  const q = questions[qIdx];
  const letters = ['A', 'B', 'C', 'D'];
  
  q.opts.forEach((_, oi) => {
    const el = document.getElementById(`opt-${chapterId}-${qIdx}-${oi}`);
    if (el) {
      el.classList.remove('selected', 'correct', 'wrong');
      if (oi === optIdx) el.classList.add('selected');
    }
  });
}

function checkAnswer(chapterId, qIdx) {
  const state = quizState[chapterId];
  if (!state) return;
  
  const selected = state.answers[qIdx];
  if (selected === undefined) {
    alert('Please select an answer first.');
    return;
  }
  
  revealAnswer(chapterId, qIdx);
}

function revealAnswer(chapterId, qIdx) {
  const state = quizState[chapterId];
  if (!state) return;
  
  state.revealed.add(qIdx);
  
  const questions = QUIZ_DATA[chapterId];
  const q = questions[qIdx];
  const selected = state.answers[qIdx];
  
  // Update option styles
  q.opts.forEach((_, oi) => {
    const el = document.getElementById(`opt-${chapterId}-${qIdx}-${oi}`);
    if (el) {
      el.classList.remove('selected', 'correct', 'wrong');
      if (oi === q.ans) {
        el.classList.add('correct');
      } else if (oi === selected) {
        el.classList.add('wrong');
      }
    }
  });
  
  // Show explanation
  const expEl = document.getElementById(`exp-${chapterId}-${qIdx}`);
  if (expEl) expEl.classList.add('show');
  
  // Update card border
  const card = document.getElementById(`qcard-${chapterId}-${qIdx}`);
  if (card) {
    card.classList.remove('answered-correct', 'answered-wrong');
    if (selected === q.ans) {
      card.classList.add('answered-correct');
    } else {
      card.classList.add('answered-wrong');
    }
  }
  
  updateScore(chapterId);
}

function checkAll(chapterId) {
  const questions = QUIZ_DATA[chapterId];
  if (!questions) return;
  
  questions.forEach((_, idx) => {
    revealAnswer(chapterId, idx);
  });
  
  showScoreBoard(chapterId);
}

function revealAll(chapterId) {
  checkAll(chapterId);
}

function resetQuiz(chapterId) {
  quizState[chapterId] = { answers: {}, revealed: new Set() };
  renderQuiz(chapterId);
  
  const scoreBoard = document.getElementById('score-board-' + chapterId);
  if (scoreBoard) scoreBoard.classList.remove('show');
  
  const scoreEl = document.getElementById('score-' + chapterId);
  if (scoreEl) scoreEl.textContent = '0/0';
}

function updateScore(chapterId) {
  const questions = QUIZ_DATA[chapterId];
  const state = quizState[chapterId];
  if (!questions || !state) return;
  
  let correct = 0;
  let answered = 0;
  
  questions.forEach((q, idx) => {
    if (state.revealed.has(idx)) {
      answered++;
      if (state.answers[idx] === q.ans) correct++;
    }
  });
  
  const scoreEl = document.getElementById('score-' + chapterId);
  if (scoreEl) scoreEl.textContent = `${correct}/${answered}`;
}

function showScoreBoard(chapterId) {
  const questions = QUIZ_DATA[chapterId];
  const state = quizState[chapterId];
  if (!questions || !state) return;
  
  let correct = 0;
  questions.forEach((q, idx) => {
    if (state.answers[idx] === q.ans) correct++;
  });
  
  const total = questions.length;
  const pct = Math.round((correct / total) * 100);
  
  const board = document.getElementById('score-board-' + chapterId);
  const pctEl = document.getElementById('score-pct-' + chapterId);
  const msgEl = document.getElementById('score-msg-' + chapterId);
  const detailEl = document.getElementById('score-detail-' + chapterId);
  
  if (board) {
    board.classList.add('show');
    board.style.setProperty('--score-pct', pct + '%');
  }
  if (pctEl) pctEl.textContent = pct + '%';
  if (msgEl) {
    if (pct >= 80) msgEl.textContent = 'üéâ Excellent! Exam-ready performance!';
    else if (pct >= 70) msgEl.textContent = 'üëç Good progress! Review missed topics.';
    else if (pct >= 60) msgEl.textContent = 'üìö Keep studying ‚Äî you\'re getting there!';
    else msgEl.textContent = 'üîÑ Review this chapter and try again.';
  }
  if (detailEl) detailEl.textContent = `${correct} correct out of ${total} questions`;
}

// ‚îÄ‚îÄ Keyboard Navigation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
document.addEventListener('keydown', (e) => {
  if (e.key === 'Escape') {
    const sidebar = document.getElementById('sidebar');
    if (sidebar.classList.contains('open')) {
      sidebar.classList.remove('open');
    }
  }
});

// ‚îÄ‚îÄ Close sidebar on outside click (mobile) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
document.addEventListener('click', (e) => {
  const sidebar = document.getElementById('sidebar');
  const menuToggle = document.getElementById('menu-toggle');
  if (sidebar.classList.contains('open') && 
      !sidebar.contains(e.target) && 
      !menuToggle.contains(e.target)) {
    sidebar.classList.remove('open');
  }
});

// ‚îÄ‚îÄ Initialize ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
document.addEventListener('DOMContentLoaded', () => {
  // Render quizzes for chapters 1 and 2 (pre-built HTML)
  renderQuiz(1);
  renderQuiz(2);
  
  // Update progress bar
  updateProgressBar();
  
  // Sticky nav active state on scroll
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        const id = entry.target.id;
        document.querySelectorAll('.sticky-nav-item').forEach(item => {
          item.classList.remove('active');
        });
        // Find matching sticky nav item
        const page = document.querySelector('.page.active');
        if (page) {
          const navItems = page.querySelectorAll('.sticky-nav-item');
          navItems.forEach(item => {
            const onclick = item.getAttribute('onclick') || '';
            if (onclick.includes(id)) {
              item.classList.add('active');
            }
          });
        }
      }
    });
  }, { rootMargin: '-130px 0px -70% 0px' });
  
  // Observe all content sections
  document.querySelectorAll('.content-section, .practice-section').forEach(el => {
    observer.observe(el);
  });
});

</script>
</body>
</html>
